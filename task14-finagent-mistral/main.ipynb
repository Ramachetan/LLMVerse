{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Agent Earnings Call Analysis System (MAECAS) - Google GenAI Version\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/YOUR_USERNAME/YOUR_REPO/blob/main/Multi_Agent_Earnings_Call_Analysis_System_GoogleGenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "This notebook implements the Multi-Agent Earnings Call Analysis System (MAECAS) using Google's Generative AI (Gemini models via Vertex AI) instead of Mistral AI.\n",
    "\n",
    "## The Problem\n",
    "\n",
    "Quarterly earnings calls provide critical insights into company performance, strategies, and outlook, but extracting meaningful analysis presents significant challenges:\n",
    "\n",
    "- Earnings call transcripts are lengthy and dense.\n",
    "- Key insights are scattered.\n",
    "- Different stakeholders need different types of information.\n",
    "- Cross-quarter analysis is manual and time-consuming.\n",
    "\n",
    "## Our Solution (using Google GenAI)\n",
    "\n",
    "MAECAS transforms how earnings calls are processed through a multi-agent workflow that:\n",
    "\n",
    "1.  Extracts insights from quarterly transcripts using specialized analysis agents powered by Gemini models.\n",
    "2.  Leverages Gemini's multi-modal capabilities for direct PDF processing.\n",
    "3.  Delivers both comprehensive reports and targeted query responses generated by Gemini.\n",
    "4.  Identifies trends and patterns across quarters using Gemini's analytical abilities.\n",
    "5.  Maintains a structured knowledge base of earnings insights.\n",
    "\n",
    "## Specialized Analysis Agents\n",
    "\n",
    "- **Financial Agent:** Extracts financial metrics.\n",
    "- **Strategic Agent:** Identifies strategic initiatives.\n",
    "- **Sentiment Agent:** Evaluates management tone.\n",
    "- **Risk Agent:** Detects challenges and risks.\n",
    "- **Competitor Agent:** Tracks competitive positioning.\n",
    "- **Temporal Agent:** Analyzes trends across quarters.\n",
    "\n",
    "## Google GenAI Models\n",
    "\n",
    "This implementation uses Google Gemini models accessed via Vertex AI:\n",
    "\n",
    "- `gemini-1.5-pro-preview-0514` (or similar Pro model): Used for structured JSON output generation (insights), PDF processing, and complex analysis (temporal trends).\n",
    "- `gemini-1.5-flash-preview-0514` (or similar Flash model): Used for faster, general text generation (report sections, summaries, query answers).\n",
    "\n",
    "*(Model names might need updating based on availability in your region/project)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "1.  **Install Libraries:**\n",
    "    ```bash\n",
    "    pip install google-cloud-aiplatform google-generativeai pydantic IPython\n",
    "    ```\n",
    "2.  **Authentication:** Authenticate your environment to Google Cloud. The easiest way for local/Colab development is:\n",
    "    ```bash\n",
    "    gcloud auth application-default login\n",
    "    ```\n",
    "    *(In Colab, you might need to run `from google.colab import auth; auth.authenticate_user()`)*\n",
    "3.  **Enable APIs:** Ensure the **Vertex AI API** is enabled in your Google Cloud project.\n",
    "4.  **Set Environment Variables:** Configure your Google Cloud Project ID and Location. Replace the placeholders below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-cloud-aiplatform google-generativeai pydantic IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Environment Variable Setup --- \n",
    "# Option 1: Set them in your system environment before launching the notebook\n",
    "# export GOOGLE_PROJECT_ID=\"your-gcp-project-id\"\n",
    "# export GOOGLE_LOCATION=\"your-gcp-region\" # e.g., us-central1\n",
    "\n",
    "# Option 2: Set them directly in the notebook (less secure for shared notebooks)\n",
    import os\n",
    \n",
    # REPLACE WITH YOUR ACTUAL PROJECT ID AND REGION\n",
    # os.environ['GOOGLE_PROJECT_ID'] = 'your-gcp-project-id' \n",
    # os.environ['GOOGLE_LOCATION'] = 'us-central1' # e.g., us-central1\n",
    \n",
    # --- Check if variables are set ---\n",
    google_project_id = os.environ.get('GOOGLE_PROJECT_ID')\n",
    google_location = os.environ.get('GOOGLE_LOCATION')\n",
    \n",
    if not google_project_id or not google_location:\n",
    "    print(\"ðŸ›‘ ERROR: Please set the GOOGLE_PROJECT_ID and GOOGLE_LOCATION environment variables.\")\n",
    "    print(\"Example:\")\n",
    "    print(\"import os\")\n",
    "    print(\"os.environ['GOOGLE_PROJECT_ID'] = 'your-gcp-project-id'\")\n",
    "    print(\"os.environ['GOOGLE_LOCATION'] = 'us-central1'\")\n",
    "    # raise ValueError(\"Environment variables not set.\") # Uncomment to stop execution\n",
    "else:\n",
    "    print(f\"âœ… Using GCP Project ID: {google_project_id}\")\n",
    "    print(f\"âœ… Using GCP Location:  {google_location}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt Colab authentication if running in Colab\n",
    "try:\n",
    "    from google.colab import auth\n",
    "    print(\"Authenticating in Google Colab...\")\n",
    "    auth.authenticate_user()\n",
    "    print(\"Colab authentication successful.\")\n",
    "except ImportError:\n",
    "    print(\"Not running in Colab or google.colab not available. Assuming local authentication (gcloud auth application-default login) is done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    import json\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Literal, Optional, Union\n",
    "from abc import ABC, abstractmethod\n",
    "import time\n",
    "import traceback\n",
    "\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# --- Google GenAI Imports ---\n",
    "try:\n",
    "    from google import generativeai as genai\n",
    "    from google.generativeai import types\n",
    "    # Use google.api_core.exceptions for specific API error handling\n",
    "    from google.api_core import exceptions as google_exceptions\n",
    "except ImportError:\n",
    "    print(\"ðŸ›‘ ERROR: Please install google-generativeai and google-cloud-aiplatform:\")\n",
    "    print(\"pip install google-generativeai google-cloud-aiplatform\")\n",
    "    # Or raise an error to stop execution\n",
    "    # raise ImportError(\"Required Google libraries not found.\") \n",
    "\n",
    "# --- Model Selection (Using Gemini Models) ---\n",
    "# Ensure these models are available in your project/location via Vertex AI Model Garden\n",
    "DEFAULT_MODEL_GOOGLE = \"gemini-1.5-flash-preview-0514\" # For general text generation\n",
    "STRUCTURED_MODEL_GOOGLE = \"gemini-1.5-pro-preview-0514\"  # For structured JSON, complex analysis\n",
    "PDF_PROCESSING_MODEL_GOOGLE = \"gemini-1.5-pro-preview-0514\" # Must support PDF input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Google GenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_client = None # Initialize as None\n",
    "if google_project_id and google_location:\n",
    "    try:\n",
    "        # Configure GenAI library to use Vertex AI endpoint\n",
    "        genai.configure(\n",
    "            client_options={\"api_endpoint\": f\"{google_location}-aiplatform.googleapis.com\"}\n",
    "        )\n",
    "        \n",
    "        # Create a client instance (can be used to call different models)\n",
    "        # We specify the project/location here for Vertex AI usage\n",
    "        google_client = genai.GenerativeModel(\n",
    "            model_name=STRUCTURED_MODEL_GOOGLE, # Default model for client, can be overridden in calls\n",
    "            # System instructions can be set globally or per-call\n",
    "            # system_instruction=\"You are a helpful AI assistant.\", \n",
    "            generation_config=types.GenerationConfig(temperature=0.1), # Default temp\n",
    "            project=google_project_id,\n",
    "            location=google_location,\n",
    "            # safety_settings=... # Optional: configure safety settings if needed\n",
    "        )\n",
    "        print(f\"âœ… Google GenAI client configured for Vertex AI project='{google_project_id}', location='{google_location}'\")\n",
    "        \n",
    "        # Optional: Simple test call to verify connectivity\n",
    "        # print(\"Performing a quick test call...\")\n",
    "        # try:\n",
    "        #    test_response = google_client.generate_content(\"Test prompt\", generation_config=types.GenerationConfig(temperature=0.0))\n",
    "        #    print(f\"Test call successful. Response snippet: {test_response.text[:50]}...\")\n",
    "        # except Exception as test_e:\n",
    "        #    print(f\"ðŸ›‘ Test call failed: {test_e}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ðŸ›‘ ERROR initializing Google GenAI client: {e}\")\n",
    "        print(\"Ensure GOOGLE_PROJECT_ID and GOOGLE_LOCATION are correct, Vertex AI API is enabled, and you have authenticated.\")\n",
    "        google_client = None # Ensure client is None if init fails\n",
    "else:\n",
    "    print(\"ðŸ›‘ Cannot initialize Google GenAI client: Project ID or Location missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Models (Pydantic)\n",
    "\n",
    "These models define the structure for the insights extracted by the agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinancialInsight(BaseModel):\n",
    "    \"\"\"Financial insights extracted from transcript\"\"\"\n",
    "    metric_name: str = Field(description=\"Name of the financial metric\")\n",
    "    value: Optional[str] = Field(description=\"Numerical or textual value of the metric\")\n",
    "    context: str = Field(description=\"Surrounding context for the metric\")\n",
    "    quarter: Literal[\"Q1\", \"Q2\", \"Q3\", \"Q4\"] = Field(description=\"Quarter the insight relates to (e.g., Q1, Q2)\")\n",
    "    confidence: float = Field(ge=0.0, le=1.0, description=\"Confidence score for the insight\")\n",
    "\n",
    "class FinancialInsightsResponse(BaseModel):\n",
    "    \"\"\"Wrapper for list of financial insights\"\"\"\n",
    "    insights: List[FinancialInsight] = Field(description=\"Collection of financial insights\")\n",
    "\n",
    "class StrategicInsight(BaseModel):\n",
    "    \"\"\"Strategic insights about business direction\"\"\"\n",
    "    initiative: str = Field(description=\"Name of the strategic initiative\")\n",
    "    description: str = Field(description=\"Details about the strategic initiative\")\n",
    "    timeframe: Optional[str] = Field(default=None, description=\"Expected timeline for implementation\")\n",
    "    quarter: Literal[\"Q1\", \"Q2\", \"Q3\", \"Q4\"] = Field(description=\"Quarter the insight relates to (e.g., Q1, Q2, Q3, Q4)\")\n",
    "    importance: int = Field(ge=1, le=5, description=\"Importance rating\")\n",
    "\n",
    "class StrategicInsightsResponse(BaseModel):\n",
    "    \"\"\"Wrapper for list of strategic insights\"\"\"\n",
    "    insights: List[StrategicInsight] = Field(description=\"Collection of strategic insights\")\n",
    "\n",
    "class SentimentInsight(BaseModel):\n",
    "    \"\"\"Insights about management sentiment\"\"\"\n",
    "    topic: str = Field(description=\"Subject matter being discussed\")\n",
    "    sentiment: Literal[\"very negative\", \"negative\", \"neutral\", \"positive\", \"very positive\"] = Field(description=\"Tone expressed by management\")\n",
    "    evidence: str = Field(description=\"Quote or context supporting the sentiment analysis\")\n",
    "    speaker: str = Field(description=\"Person who expressed the sentiment (e.g., CEO, CFO, Analyst Name)\")\n",
    "    quarter: Literal[\"Q1\", \"Q2\", \"Q3\", \"Q4\"] = Field(description=\"Quarter the insight relates to (e.g., Q1, Q2, Q3, Q4)\")\n",
    "\n",
    "class SentimentInsightsResponse(BaseModel):\n",
    "    \"\"\"Wrapper for list of sentiment insights\"\"\"\n",
    "    insights: List[SentimentInsight] = Field(description=\"Collection of sentiment insights\")\n",
    "\n",
    "class RiskInsight(BaseModel):\n",
    "    \"\"\"Identified risks or challenges\"\"\"\n",
    "    risk_factor: str = Field(description=\"Name or type of risk identified\")\n",
    "    description: str = Field(description=\"Details about the risk\")\n",
    "    potential_impact: str = Field(description=\"Possible consequences of the risk\")\n",
    "    mitigation_mentioned: Optional[str] = Field(default=None, description=\"Strategies mentioned to address the risk\")\n",
    "    quarter: Literal[\"Q1\", \"Q2\", \"Q3\", \"Q4\"] = Field(description=\"Quarter the insight relates to (e.g., Q1, Q2, Q3, Q4)\")\n",
    "    severity: int = Field(ge=1, le=5, description=\"Severity rating (1=low, 5=high)\")\n",
    "\n",
    "class RiskInsightsResponse(BaseModel):\n",
    "    \"\"\"Wrapper for list of risk insights\"\"\"\n",
    "    insights: List[RiskInsight] = Field(description=\"Collection of risk insights\")\n",
    "\n",
    "class CompetitorInsight(BaseModel):\n",
    "    \"\"\"Insights about competitive positioning\"\"\"\n",
    "    competitor: Optional[str] = Field(default=None, description=\"Name of the competitor company if specified\")\n",
    "    market_segment: str = Field(description=\"Specific market area being discussed\")\n",
    "    positioning: str = Field(description=\"Statement about competitive stance or market position\")\n",
    "    quarter: Literal[\"Q1\", \"Q2\", \"Q3\", \"Q4\"] = Field(description=\"Quarter the insight relates to (e.g., Q1, Q2, Q3, Q4)\")\n",
    "    mentioned_by: str = Field(description=\"Person who mentioned the competitive information (e.g., CEO, Analyst)\")\n",
    "\n",
    "class CompetitorInsightsResponse(BaseModel):\n",
    "    \"\"\"Wrapper for list of competitor insights\"\"\"\n",
    "    insights: List[CompetitorInsight] = Field(description=\"Collection of competitor insights\")\n",
    "\n",
    "class TemporalInsight(BaseModel):\n",
    "    \"\"\"Insights about trends across quarters\"\"\"\n",
    "    trend_type: Literal[\"growth\", \"decline\", \"stable\", \"volatile\", \"emerging\", \"fading\"] = Field(description=\"Direction or pattern of the trend\")\n",
    "    topic: str = Field(description=\"Subject matter of the trend (e.g., Revenue Growth, AI Strategy)\")\n",
    "    description: str = Field(description=\"Explanation of the trend and its significance\")\n",
    "    quarters_observed: List[Literal[\"Q1\", \"Q2\", \"Q3\", \"Q4\"]] = Field(description=\"Quarters where the trend is evident in the data\")\n",
    "    supporting_evidence: str = Field(description=\"Brief summary of data or quotes supporting the trend identification from the provided insights\")\n",
    "\n",
    "class TemporalInsightsResponse(BaseModel):\n",
    "    \"\"\"Wrapper for list of temporal insights\"\"\"\n",
    "    insights: List[TemporalInsight] = Field(description=\"Collection of temporal insights\")\n",
    "\n",
    "class QueryAnalysis(BaseModel):\n",
    "    \"\"\"Analysis of user query to determine required components\"\"\"\n",
    "    quarters: List[Literal[\"Q1\", \"Q2\", \"Q3\", \"Q4\"]] = Field(description=\"List of relevant quarters (e.g., ['Q1', 'Q2'])\")\n",
    "    agent_types: List[Literal[\"Financial\", \"Strategic\", \"Sentiment\", \"Risk\", \"Competitor\"]] = Field(description=\"List of agent types needed (e.g., ['Financial', 'Risk'])\")\n",
    "    temporal_analysis_required: bool = Field(description=\"Whether comparison or trends across quarters are needed\")\n",
    "    query_intent: str = Field(description=\"Brief description of the user's core question\")\n",
    "\n",
    "# Note: ReportSection is not used for structured output from LLM, but for internal organization\n",
    "class ReportSection(BaseModel):\n",
    "    \"\"\"Internal structure for a section of the final report\"\"\"\n",
    "    title: str\n",
    "    content: str\n",
    "    subsections: Optional[List['ReportSection']] = None # Keep for potential future use\n",
    "\n",
    "# Update forward refs if using older Pydantic\n",
    "# ReportSection.update_forward_refs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function for Robust API Calls\n",
    "\n",
    "Handles retries with exponential backoff for common API errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_content_with_retry(\n",
    "    client: genai.GenerativeModel, # Pass the initialized client\n",
    "    model_name: str,              # Specify the model to use for this call\n",
    "    contents: List[Union[str, types.Part, Dict]], # Accept dicts for content structure too\n",
    "    generation_config: types.GenerationConfig,\n",
    "    max_retries: int = 3,\n",
    "    initial_delay: float = 2.0, # Start with slightly longer delay\n",
    "    stream: bool = False # Add stream option\n",
    "    ):\n",
    "    \"\"\"Calls generate_content with exponential backoff for retries.\"\"\"\n",
    "    retries = 0\n",
    "    delay = initial_delay\n",
    "    \n",
    "    # Get a model instance specifically for this call's model_name\n",
    "    # This ensures we use the correct model and its associated settings\n",
    "    try:\n",
    "         model_instance = genai.GenerativeModel(\n",
    "             model_name=model_name,\n",
    "             generation_config=generation_config, \n",
    "             project=client.project, # Use project/location from the base client\n",
    "             location=client.location,\n",
    "             # Inherit other settings like safety, tools if configured on base client\n",
    "             # safety_settings=client.safety_settings, \n",
    "             # tools=client.tools\n",
    "         )\n",
    "    except Exception as model_init_error:\n",
    "         print(f\"ðŸ›‘ ERROR: Failed to initialize model instance for '{model_name}': {model_init_error}\")\n",
    "         raise\n",
    "\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            print(f\"Attempting API call to {model_name} (Attempt {retries + 1}/{max_retries})...\")\n",
    "            response = model_instance.generate_content(\n",
    "                contents=contents,\n",
    "                generation_config=generation_config, # Pass config again (might be redundant, check SDK)\n",
    "                stream=stream \n",
    "            )\n",
    "            \n",
    "            # --- Response Validation (for non-streaming) ---\n",
    "            if not stream:\n",
    "                # Check for blocking immediately\n",
    "                if response.prompt_feedback.block_reason:\n",
    "                    raise ValueError(f\"Content blocked due to {response.prompt_feedback.block_reason.name}. Review prompt/content and safety settings.\")\n",
    "                \n",
    "                # Check if response structure is as expected\n",
    "                if not response.candidates:\n",
    "                    # Sometimes API returns success but empty candidates\n",
    "                    raise ValueError(\"API Error: Response received successfully but contains no candidates.\")\n",
    "                if not response.candidates[0].content or not response.candidates[0].content.parts:\n",
    "                    # Check if the content is empty or has finish_reason=SAFETY etc.\n",
    "                    finish_reason = response.candidates[0].finish_reason\n",
    "                    if finish_reason != types.Candidate.FinishReason.STOP:\n",
    "                         raise ValueError(f\"API Error: Response generation finished unexpectedly due to {finish_reason.name}.\")\n",
    "                    else:\n",
    "                         # It might be a valid empty response in some cases, but often indicates an issue\n",
    "                         # Allow it for now, but downstream checks needed\n",
    "                         print(f\"Warning: API response part is empty for model {model_name}. Finish Reason: {finish_reason.name}\")\n",
    "                         # Consider raising ValueError if empty text is always an error for your use case\n",
    "                         # raise ValueError(\"API response is empty or missing expected content parts.\")\n",
    "            \n",
    "            print(f\"API call to {model_name} successful.\")\n",
    "            return response\n",
    "\n",
    "        # --- Error Handling & Retries ---\n",
    "        # Specific Google API errors first\n",
    "        except google_exceptions.ResourceExhausted as e: # Quota errors\n",
    "            error_message = f\"API Quota Error ({type(e).__name__}): {e}.\"\n",
    "        except google_exceptions.ServiceUnavailable as e: # Temporary server issues\n",
    "            error_message = f\"API Service Unavailable Error ({type(e).__name__}): {e}.\"\n",
    "        except google_exceptions.InternalServerError as e: # Google-side errors\n",
    "            error_message = f\"API Internal Server Error ({type(e).__name__}): {e}.\"\n",
    "        except google_exceptions.DeadlineExceeded as e:\n",
    "             error_message = f\"API Deadline Exceeded Error ({type(e).__name__}): {e}.\"\n",
    "        # Specific ValueError for blocked content (don't retry)\n",
    "        except ValueError as e:\n",
    "            print(f\"ValueError during API call processing: {e}\")\n",
    "            raise # Re-raise value errors immediately (blocked content, unexpected finish reason, etc.)\n",
    "        # Catch other potential google API errors\n",
    "        except google_exceptions.GoogleAPIError as e:\n",
    "             error_message = f\"Google API Error ({type(e).__name__}): {e}.\"\n",
    "        # Catch broader network/connection issues\n",
    "        except ConnectionError as e:\n",
    "             error_message = f\"Network/Connection Error ({type(e).__name__}): {e}.\"\n",
    "        # Catch any other unexpected exceptions during the API call\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred during API call to {model_name}: {type(e).__name__}: {e}\")\n",
    "            traceback.print_exc() # Log traceback for unexpected errors\n",
    "            raise # Re-raise other critical unexpected errors immediately\n",
    "\n",
    "        # --- Retry Logic ---\n",
    "        retries += 1\n",
    "        if retries >= max_retries:\n",
    "            print(f\"ðŸ›‘ {error_message} Max retries ({max_retries}) reached for {model_name}. Failing call.\")\n",
    "            raise ConnectionError(f\"API call to {model_name} failed after {max_retries} retries. Last error: {error_message}\") from e\n",
    "        else:\n",
    "            print(f\"âš ï¸ {error_message} Retrying ({retries}/{max_retries}) in {delay:.2f} seconds...\")\n",
    "            time.sleep(delay)\n",
    "            delay *= 2 # Exponential backoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Parser\n",
    "\n",
    "Uses Gemini's multi-modal capabilities to directly extract text from PDF files. Includes caching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDFParser:\n",
    "    \"\"\"Parse a transcript PDF file and extract text using Gemini.\"\"\"\n",
    "\n",
    "    CACHE_DIR = Path(\"transcript_cache_google\") # Use a different cache dir\n",
    "\n",
    "    @staticmethod\n",
    "    def _ensure_cache_dir():\n",
    "        \"\"\"Make sure cache directory exists\"\"\"\n",
    "        PDFParser.CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_cache_path(file_path: str) -> Path:\n",
    "        \"\"\"Get the path for a cached transcript file based on filename\"\"\"\n",
    "        file_name = Path(file_path).name\n",
    "        file_hash = hashlib.md5(file_name.encode()).hexdigest()\n",
    "        return PDFParser.CACHE_DIR / f\"{file_hash}_{file_name}.txt\"\n",
    "\n",
    "    @staticmethod\n",
    "    def read_transcript(file_path: str, client: genai.GenerativeModel, model_name: str = PDF_PROCESSING_MODEL_GOOGLE) -> str:\n",
    "        \"\"\"Extract text from PDF transcript using Gemini.\"\"\"\n",
    "        pdf_path = Path(file_path)\n",
    "        if not pdf_path.exists():\n",
    "             raise FileNotFoundError(f\"PDF file not found: {file_path}\")\n",
    "        if not pdf_path.is_file():\n",
    "             raise ValueError(f\"Path is not a file: {file_path}\")\n",
    "\n",
    "        print(f\"Processing PDF file with Gemini ({model_name}): {file_path}\")\n",
    "\n",
    "        try:\n",
    "            # Read PDF bytes\n",
    "            with open(pdf_path, \"rb\") as f:\n",
    "                pdf_bytes = f.read()\n",
    "            \n",
    "            # Create the Part for the API call\n",
    "            pdf_part = types.Part.from_data(data=pdf_bytes, mime_type=\"application/pdf\")\n",
    "\n",
    "            # Prepare the prompt for text extraction\n",
    "            prompt = \"Extract all text content from the provided PDF document. Preserve paragraphs and structure as accurately as possible. Output only the extracted text.\"\n",
    "            contents = [prompt, pdf_part] # Order matters: prompt first, then data\n",
    "\n",
    "            # Configure generation for deterministic text extraction\n",
    "            generation_config = types.GenerationConfig(\n",
    "                temperature=0.0,\n",
    "                response_mime_type=\"text/plain\" # Expect plain text output\n",
    "            )\n",
    "\n",
    "            # Make the API call using the robust helper\n",
    "            response = generate_content_with_retry(\n",
    "                client=client, \n",
    "                model_name=model_name, # Use the specified PDF processing model\n",
    "                contents=contents,\n",
    "                generation_config=generation_config\n",
    "            )\n",
    "\n",
    "            # --- Extract Text --- \n",
    "            # Access text safely, checking for potential None or empty response\n",
    "            extracted_text = \"\"\n",
    "            if response and response.text:\n",
    "                extracted_text = response.text\n",
    "                print(f\"âœ… Successfully extracted text from {file_path} ({len(extracted_text)} chars)\")\n",
    "            elif response and response.candidates and response.candidates[0].content.parts:\n",
    "                 # If .text is somehow empty but parts exist (unlikely for text/plain)\n",
    "                 extracted_text = \"\\n\".join(part.text for part in response.candidates[0].content.parts if hasattr(part, 'text'))\n",
    "                 if extracted_text:\n",
    "                      print(f\"âœ… Extracted text from response parts for {file_path} ({len(extracted_text)} chars)\")\n",
    "                 else:\n",
    "                      print(f\"âš ï¸ Warning: Gemini response for {file_path} appears empty despite successful call.\")\n",
    "            else:\n",
    "                 # This case should ideally be caught by generate_content_with_retry's validation\n",
    "                 print(f\"âš ï¸ Warning: Gemini response for {file_path} did not contain expected text structure.\")\n",
    "\n",
    "            return extracted_text\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "             print(f\"ðŸ›‘ ERROR: {e}\")\n",
    "             raise\n",
    "        except Exception as e:\n",
    "            print(f\"ðŸ›‘ ERROR processing PDF {file_path} with Gemini: {type(e).__name__}: {e}\")\n",
    "            traceback.print_exc()\n",
    "            raise # Re-raise the exception to signal failure\n",
    "\n",
    "    @staticmethod\n",
    "    def get_transcript_by_quarter(company: str, quarter: str, year: str, client: genai.GenerativeModel) -> str:\n",
    "        \"\"\"Get the transcript for a specific quarter, using cache or Gemini.\"\"\"\n",
    "        company_lower = company.lower()\n",
    "        file_path_str = f\"{company_lower}_earnings_{year}_{quarter}.pdf\"\n",
    "        \n",
    "        PDFParser._ensure_cache_dir()\n",
    "        cache_path = PDFParser._get_cache_path(file_path_str)\n",
    "\n",
    "        # Check cache first\n",
    "        if cache_path.exists() and cache_path.stat().st_size > 100: # Basic check for non-empty cache\n",
    "            print(f\"âœ… Using cached transcript: {cache_path}\")\n",
    "            try:\n",
    "                with open(cache_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    return f.read()\n",
    "            except Exception as e:\n",
    "                 print(f\"âš ï¸ Warning: Error reading cache file {cache_path}: {e}. Will re-parse.\")\n",
    "        \n",
    "        # If not in cache or cache read failed, parse with Gemini\n",
    "        try:\n",
    "            print(f\"Parsing transcript using Gemini for {company} {year} {quarter}...\")\n",
    "            transcript = PDFParser.read_transcript(file_path_str, client)\n",
    "\n",
    "            # Save to cache if transcript is not empty\n",
    "            if transcript:\n",
    "                try:\n",
    "                    with open(cache_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                        f.write(transcript)\n",
    "                    print(f\"âœ… Cached transcript: {cache_path}\")\n",
    "                except IOError as e:\n",
    "                     print(f\"âš ï¸ Warning: Could not write to cache file {cache_path}: {e}\")\n",
    "            else:\n",
    "                 print(f\"âš ï¸ Warning: No text extracted from {file_path_str}. Cache file will not be created.\")\n",
    "                 \n",
    "            return transcript\n",
    "        \n",
    "        except FileNotFoundError:\n",
    "             print(f\"ðŸ›‘ ERROR: PDF file '{file_path_str}' not found. Cannot process {quarter}.\")\n",
    "             return \"\" # Return empty string if file not found\n",
    "        except Exception as e:\n",
    "            # Catch errors from read_transcript\n",
    "            print(f\"ðŸ›‘ ERROR getting transcript for {quarter}: {str(e)}\")\n",
    "            return \"\" # Return empty string on failure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights Storage\n",
    "\n",
    "A simple JSON-based store to persist extracted insights, avoiding redundant processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InsightsStore:\n",
    "    \"\"\"Centralized storage for insights across all quarters and analysis types.\"\"\"\n",
    "\n",
    "    def __init__(self, company: str, year: str):\n",
    "        self.company = company.lower()\n",
    "        self.year = year\n",
    "        self.db_path = Path(f\"{self.company}_{self.year}_insights_google.json\") # Different DB file\n",
    "        self.insights = self._load_insights()\n",
    "        print(f\"InsightsStore initialized. Using database file: {self.db_path}\")\n",
    "\n",
    "    def _load_insights(self) -> Dict:\n",
    "        \"\"\"Load insights from database file or initialize if not exists.\"\"\"\n",
    "        if self.db_path.exists():\n",
    "            print(f\"Loading existing insights from {self.db_path}...\")\n",
    "            try:\n",
    "                with open(self.db_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    data = json.load(f)\n",
    "                    # Basic validation of top-level structure\n",
    "                    expected_keys = {\"financial\", \"strategic\", \"sentiment\", \"risk\", \"competitor\", \"temporal\"}\n",
    "                    if isinstance(data, dict) and expected_keys.issubset(data.keys()):\n",
    "                        print(\"Insights loaded successfully.\")\n",
    "                        return data\n",
    "                    else:\n",
    "                        print(f\"âš ï¸ Warning: Invalid structure found in {self.db_path}. Initializing empty store.\")\n",
    "                        return self._initialize_empty()\n",
    "            except json.JSONDecodeError:\n",
    "                 print(f\"âš ï¸ Warning: Could not decode JSON from {self.db_path}. Initializing empty store.\")\n",
    "                 return self._initialize_empty()\n",
    "            except Exception as e:\n",
    "                 print(f\"ðŸ›‘ Error loading insights from {self.db_path}: {e}. Initializing empty store.\")\n",
    "                 return self._initialize_empty()\n",
    "        else:\n",
    "            print(\"No existing insights database found. Initializing empty store.\")\n",
    "            return self._initialize_empty()\n",
    "\n",
    "    def _initialize_empty(self) -> Dict:\n",
    "         \"\"\"Returns the structure for an empty insights store.\"\"\"\n",
    "         return {\n",
    "                \"financial\": {}, \"strategic\": {}, \"sentiment\": {},\n",
    "                \"risk\": {}, \"competitor\": {}, \"temporal\": {}\n",
    "            }\n",
    "\n",
    "    def save_insights(self):\n",
    "        \"\"\"Save insights to database file.\"\"\"\n",
    "        print(f\"Saving insights to {self.db_path}...\")\n",
    "        try:\n",
    "            # Create parent directory if it doesn't exist (though Path usually handles this)\n",
    "            self.db_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            with open(self.db_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                # Use Pydantic's recommended model_dump for serialization if insights are models\n",
    "                # If insights are already dicts (as stored), direct dump is fine\n",
    "                json.dump(self.insights, f, indent=2, ensure_ascii=False)\n",
    "            print(\"Insights saved successfully.\")\n",
    "        except Exception as e:\n",
    "             print(f\"ðŸ›‘ Error saving insights to {self.db_path}: {e}\")\n",
    "             traceback.print_exc()\n",
    "\n",
    "    def add_insights(self, insight_type: str, quarter: str, new_insights: List[BaseModel]):\n",
    "        \"\"\"Add insights (Pydantic models) for a specific type and quarter.\"\"\"\n",
    "        if not new_insights:\n",
    "             print(f\"No new insights provided for {insight_type}/{quarter}. Nothing to add.\")\n",
    "             return\n",
    "             \n",
    "        print(f\"Adding {len(new_insights)} insights for {insight_type}/{quarter}...\")\n",
    "        \n",
    "        # Ensure the basic structure exists\n",
    "        if insight_type not in self.insights:\n",
    "             self.insights[insight_type] = {}\n",
    "        if quarter not in self.insights[insight_type]:\n",
    "            self.insights[insight_type][quarter] = []\n",
    "            \n",
    "        # Ensure the storage for the quarter is a list\n",
    "        if not isinstance(self.insights[insight_type][quarter], list):\n",
    "            print(f\"Warning: Overwriting non-list data structure for {insight_type}/{quarter}.\")\n",
    "            self.insights[insight_type][quarter] = []\n",
    "\n",
    "        # Convert Pydantic models to dictionaries for JSON serialization\n",
    "        try:\n",
    "            insight_dicts = [insight.model_dump(mode='json') for insight in new_insights]\n",
    "            # Use extend to add new insights to any existing ones for that quarter/type\n",
    "            self.insights[insight_type][quarter].extend(insight_dicts)\n",
    "            print(f\"Added {len(insight_dicts)} insights. Total for {insight_type}/{quarter}: {len(self.insights[insight_type][quarter])}\")\n",
    "            self.save_insights()\n",
    "        except AttributeError as e:\n",
    "             print(f\"ðŸ›‘ Error: Input insights might not be Pydantic models? {e}\")\n",
    "        except Exception as e:\n",
    "             print(f\"ðŸ›‘ Error converting or adding insights: {e}\")\n",
    "             traceback.print_exc()\n",
    "\n",
    "    def get_insights(self, insight_type: Optional[str] = None, quarters: Optional[List[str]] = None) -> Union[Dict, List[Dict]]:\n",
    "        \"\"\"Retrieve insights (as dicts), optionally filtered by type and quarters.\"\"\"\n",
    "        \n",
    "        # Handle request for all insights\n",
    "        if insight_type is None:\n",
    "            # Return a deep copy if mutation is a concern, otherwise direct access is faster\n",
    "            # import copy; return copy.deepcopy(self.insights)\n",
    "            return self.insights \n",
    "        \n",
    "        # Handle request for a specific insight type\n",
    "        if insight_type not in self.insights:\n",
    "             # print(f\"Warning: Insight type '{insight_type}' not found in store.\")\n",
    "             return {} # Return empty dict if type doesn't exist\n",
    "             \n",
    "        insights_of_type = self.insights[insight_type]\n",
    "        \n",
    "        # Return all quarters for the type if no specific quarters requested\n",
    "        if quarters is None:\n",
    "            return insights_of_type\n",
    "\n",
    "        # Filter by specified quarters\n",
    "        # Ensure quarters is a list\n",
    "        if isinstance(quarters, str):\n",
    "            quarters = [quarters]\n",
    "            \n",
    "        filtered_insights = {}\n",
    "        for q in quarters:\n",
    "            if q in insights_of_type:\n",
    "                filtered_insights[q] = insights_of_type[q]\n",
    "            # else:\n",
    "                # print(f\"Info: Quarter '{q}' not found for insight type '{insight_type}'.\")\n",
    "        \n",
    "        return filtered_insights\n",
    "\n",
    "    def get_insights_as_models(self, insight_type: str, quarters: List[str], model_class: type[BaseModel]) -> Dict[str, List[BaseModel]]:\n",
    "        \"\"\"Retrieve insights deserialized back into Pydantic models.\"\"\"\n",
    "        # print(f\"Retrieving insights as {model_class.__name__} models for {insight_type} in {quarters}...\")\n",
    "        raw_insights_dict = self.get_insights(insight_type, quarters)\n",
    "        models_dict = {}\n",
    "        \n",
    "        if not raw_insights_dict:\n",
    "             # print(\"No raw insights found for the specified criteria.\")\n",
    "             return {}\n",
    "             \n",
    "        for quarter, insight_list in raw_insights_dict.items():\n",
    "            models_dict[quarter] = []\n",
    "            if not isinstance(insight_list, list):\n",
    "                 print(f\"âš ï¸ Warning: Expected a list of insights for {insight_type}/{quarter}, but got {type(insight_list)}. Skipping quarter.\")\n",
    "                 continue\n",
    "                 \n",
    "            for insight_data in insight_list:\n",
    "                if not isinstance(insight_data, dict):\n",
    "                     print(f\"âš ï¸ Warning: Expected a dict for insight data in {insight_type}/{quarter}, but got {type(insight_data)}. Skipping insight.\")\n",
    "                     continue\n",
    "                     \n",
    "                try:\n",
    "                    # Validate and create the Pydantic model instance\n",
    "                    model_instance = model_class(**insight_data)\n",
    "                    models_dict[quarter].append(model_instance)\n",
    "                except ValidationError as e:\n",
    "                    print(f\"âš ï¸ Warning: Skipping insight due to Pydantic validation error in {quarter}, {insight_type}: {e}\")\n",
    "                    # print(f\"Problematic data: {insight_data}\") # Uncomment for debugging\n",
    "                except Exception as e:\n",
    "                     print(f\"ðŸ›‘ Error creating Pydantic model instance for {insight_type}/{quarter}: {e}\")\n",
    "                     # print(f\"Problematic data: {insight_data}\")\n",
    "                     \n",
    "        # print(f\"Retrieved {sum(len(v) for v in models_dict.values())} models.\")\n",
    "        return models_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specialized Agents\n",
    "\n",
    "Define the base agent class and the specialized agents (Financial, Strategic, etc.), refactored to use Gemini for analysis and structured JSON output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(ABC):\n",
    "    \"\"\"Base class for all specialized agents.\"\"\"\n",
    "    # No client stored here, passed during analysis\n",
    "\n",
    "    @abstractmethod\n",
    "    def analyze(self, transcript: str, quarter: str, client: genai.GenerativeModel) -> List[BaseModel]:\n",
    "        \"\"\"Analyze the transcript and return a list of Pydantic insight models.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def _generate_json_insights(\n",
    "        self,\n",
    "        client: genai.GenerativeModel,\n",
    "        system_prompt: str,\n",
    "        user_prompt: str,\n",
    "        response_model: type[BaseModel], # The Pydantic *Wrapper* model (e.g., FinancialInsightsResponse)\n",
    "        model_name: str = STRUCTURED_MODEL_GOOGLE,\n",
    "        temperature: float = 0.1,\n",
    "        max_retries: int = 3\n",
    "    ) -> List[BaseModel]:\n",
    "        \"\"\"Helper to generate and parse JSON insights using Gemini, returning the list of individual insights.\"\"\"\n",
    "        \n",
    "        # Construct the full prompt with JSON instructions\n",
    "        json_schema = response_model.model_json_schema(indent=2)\n",
    "        json_instruction = f\"\"\"\n",
    "You MUST respond ONLY with a valid JSON object that strictly adheres to the following Pydantic schema. Do NOT include any other text, explanations, or markdown formatting (like ```json) before or after the JSON object itself.\n",
    "\n",
    "Schema:\n",
    "```json\n",
    "{json_schema}\n",
    "```\n",
    "\"\"\"        \n",
    "        # Combine system prompt, user prompt, and JSON instructions\n",
    "        # Gemini generally takes a list of Contents or Parts\n",
    "        # A common pattern is a system message (often via model config) and then user message\n",
    "        # Here, we combine system + JSON instruction into the first 'user' turn for simplicity, \n",
    "        # assuming no dedicated system prompt role is being used via client config.\n",
    "        full_user_prompt = f\"{system_prompt}\\n\\n{json_instruction}\\n\\nUser Request:\\n{user_prompt}\"\n",
    "        \n",
    "        contents = [full_user_prompt] # Simple list of strings for basic cases\n",
    "        \n",
    "        generation_config = types.GenerationConfig(\n",
    "            temperature=temperature,\n",
    "            response_mime_type=\"application/json\" # CRITICAL: Request JSON output\n",
    "        )\n",
    "\n",
    "        response_text = \"\"\n",
    "        parsed_json = None\n",
    "        retries = 0\n",
    "        while retries < max_retries:\n",
    "            try:\n",
    "                response = generate_content_with_retry(\n",
    "                    client=client,\n",
    "                    model_name=model_name,\n",
    "                    contents=contents,\n",
    "                    generation_config=generation_config\n",
    "                )\n",
    "                \n",
    "                # --- JSON Parsing and Validation ---\n",
    "                response_text = response.text.strip()\n",
    "                \n",
    "                # Attempt to handle cases where the model might still wrap in markdown\n",
    "                if response_text.startswith(\"```json\"): response_text = response_text[7:-3].strip()\n",
    "                elif response_text.startswith(\"```\"): response_text = response_text[3:-3].strip()\n",
    "                \n",
    "                if not response_text:\n",
    "                    print(f\"Warning: Received empty response text from {model_name}. Cannot parse JSON.\")\n",
    "                    return [] # Return empty list if response is empty\n",
    "                    \n",
    "                # Parse the JSON string\n",
    "                parsed_json = json.loads(response_text)\n",
    "                \n",
    "                # Validate the parsed JSON against the Pydantic wrapper model\n",
    "                validated_response = response_model(**parsed_json)\n",
    "                \n",
    "                # Return the list of individual insight models\n",
    "                if hasattr(validated_response, 'insights') and isinstance(validated_response.insights, list):\n",
    "                     print(f\"âœ… Successfully parsed and validated {len(validated_response.insights)} insights.\")\n",
    "                     return validated_response.insights\n",
    "                else:\n",
    "                     print(f\"ðŸ›‘ Error: Validated response object does not have an 'insights' list attribute.\")\n",
    "                     return [] # Return empty list if structure is wrong\n",
    "\n",
    "            # --- Error Handling within Retry Loop ---\n",
    "            except json.JSONDecodeError as e:\n",
    "                error_context = f\"JSONDecodeError (Attempt {retries + 1}/{max_retries})\"\n",
    "                print(f\"ðŸ›‘ {error_context}: {e}\")\n",
    "                print(f\"Received text (first 500 chars): '{response_text[:500]}...'\" if response_text else \"Received empty text.\")\n",
    "            except ValidationError as e:\n",
    "                error_context = f\"Pydantic ValidationError (Attempt {retries + 1}/{max_retries})\"\n",
    "                print(f\"ðŸ›‘ {error_context}: {e}\")\n",
    "                # print(f\"Parsed JSON: {parsed_json}\") # Uncomment for debugging\n",
    "            except Exception as e:\n",
    "                # Catch errors from generate_content_with_retry or other unexpected issues\n",
    "                error_context = f\"Unexpected Error (Attempt {retries + 1}/{max_retries})\"\n",
    "                print(f\"ðŸ›‘ {error_context} in _generate_json_insights: {type(e).__name__}: {e}\")\n",
    "                traceback.print_exc()\n",
    "                # For critical errors caught by the retry helper (like blocking), we might have already raised.\n",
    "                # If we reach here due to another error, decide whether to retry.\n",
    "                # Let's retry unless it's a clear data/validation issue caught above.\n",
    "                \n",
    "            # --- Retry Logic ---\n",
    "            retries += 1\n",
    "            if retries >= max_retries:\n",
    "                print(f\"ðŸ›‘ Max retries reached for {error_context}. Returning empty list.\")\n",
    "                return [] # Return empty list on persistent failure\n",
    "            print(f\"Waiting {1 + retries} seconds before retrying...\")\n",
    "            time.sleep(1 + retries) # Simple incremental backoff\n",
    "            \n",
    "        # Fallback if loop finishes without success (shouldn't normally happen)\n",
    "        return []\n",
    "\n",
    "# --- Agent Implementations ---\n",
    "\n",
    "class FinancialAgent(Agent):\n",
    "    def analyze(self, transcript: str, quarter: str, client: genai.GenerativeModel) -> List[FinancialInsight]:\n",
    "        system_prompt = f\"\"\"\n",
    "        You are a meticulous financial analyst. Your task is to extract key financial metrics and performance indicators from the provided earnings call transcript for quarter {quarter}.\n",
    "        Focus ONLY on extracting explicitly stated figures and facts related to:\n",
    "        - Revenue (overall, by segment, geographical)\n",
    "        - Profit Margins (Gross, Operating, Net)\n",
    "        - Earnings Per Share (EPS - GAAP and non-GAAP if specified)\n",
    "        - Growth Rates (YoY, QoQ for revenue, margins, EPS, etc.)\n",
    "        - Forward Guidance (Explicit ranges or targets for revenue, margins, EPS for next quarter/year)\n",
    "        - Capital Expenditures (CapEx)\n",
    "        - Cash Flow (Operating, Free Cash Flow, Cash Balance)\n",
    "        - Debt levels, Share Buybacks, Dividends\n",
    "        - Key Performance Indicators (KPIs) explicitly mentioned (e.g., Bookings, ARR, Active Users)\n",
    "        \n",
    "        Instructions:\n",
    "        - Extract only NUMERICAL data or specific guidance statements.\n",
    "        - Include currency (e.g., USD, $) if mentioned in the context.\n",
    "        - Provide brief context around the metric.\n",
    "        - Set 'confidence' to 1.0 for clearly stated numbers/ranges, or slightly lower (e.g., 0.8-0.9) if interpretation is needed (but prioritize explicit facts).\n",
    "        - Ensure the 'quarter' field is correctly set to '{quarter}'.\n",
    "        \"\"\"\n",
    "        user_prompt = f\"Transcript for {quarter}:\n{transcript}\"\n",
    "        print(f\"FinancialAgent: Extracting insights for {quarter} using {STRUCTURED_MODEL_GOOGLE}...\")\n",
    "        insights = self._generate_json_insights(\n",
    "            client=client,\n",
    "            system_prompt=system_prompt,\n",
    "            user_prompt=user_prompt,\n",
    "            response_model=FinancialInsightsResponse, # Expecting the wrapper model\n",
    "            model_name=STRUCTURED_MODEL_GOOGLE,\n",
    "            temperature=0.0 # Deterministic for financial facts\n",
    "        )\n",
    "        print(f\"FinancialAgent: Completed for {quarter}. Found {len(insights)} insights.\")\n",
    "        return insights\n",
    "\n",
    "class StrategicAgent(Agent):\n",
    "    def analyze(self, transcript: str, quarter: str, client: genai.GenerativeModel) -> List[StrategicInsight]:\n",
    "        system_prompt = f\"\"\"\n",
    "        You are a business strategy analyst. Your task is to identify and extract concrete strategic initiatives, plans, and directions from the earnings call transcript for quarter {quarter}.\n",
    "        Focus on:\n",
    "        - New product launches, updates, or specific roadmap details (mention product names/features).\n",
    "        - Market expansion plans (new geographies, customer segments, verticals).\n",
    "        - Strategic partnerships, collaborations, or M&A activity mentioned.\n",
    "        - Key R&D focus areas, significant investments, or technological advancements discussed.\n",
    "        - Statements about long-term vision or shifts in core strategy.\n",
    "        - Changes to business models, pricing, or go-to-market approaches.\n",
    "        - Explicit mentions of focus on specific market segments or technologies.\n",
    "        \n",
    "        Instructions:\n",
    "        - Extract specific, actionable initiatives, not vague statements.\n",
    "        - Provide a clear description of the initiative.\n",
    "        - Note the timeframe if explicitly mentioned.\n",
    "        - Assign an 'importance' score (1-5, 5=most important) based on management emphasis, repetition, or stated impact.\n",
    "        - Ensure the 'quarter' field is correctly set to '{quarter}'.\n",
    "        \"\"\"\n",
    "        user_prompt = f\"Transcript for {quarter}:\n{transcript}\"\n",
    "        print(f\"StrategicAgent: Extracting insights for {quarter} using {STRUCTURED_MODEL_GOOGLE}...\")\n",
    "        insights = self._generate_json_insights(\n",
    "            client=client,\n",
    "            system_prompt=system_prompt,\n",
    "            user_prompt=user_prompt,\n",
    "            response_model=StrategicInsightsResponse,\n",
    "            model_name=STRUCTURED_MODEL_GOOGLE,\n",
    "            temperature=0.1 # Allow slight flexibility for interpretation\n",
    "        )\n",
    "        print(f\"StrategicAgent: Completed for {quarter}. Found {len(insights)} insights.\")\n",
    "        return insights\n",
    "\n",
    "class SentimentAgent(Agent):\n",
    "    def analyze(self, transcript: str, quarter: str, client: genai.GenerativeModel) -> List[SentimentInsight]:\n",
    "        system_prompt = f\"\"\"\n",
    "        You are an expert analyst specializing in discerning sentiment and tone within corporate communications like earnings calls. Analyze the transcript for quarter {quarter}.\n",
    "        Focus on identifying the sentiment expressed by specific speakers (e.g., CEO, CFO, named analysts) regarding particular topics.\n",
    "        Look for:\n",
    "        - Confidence levels expressed (high, low, cautious) regarding guidance, product lines, competition, execution, etc.\n",
    "        - Tone (very positive, positive, neutral, negative, very negative) when discussing specific business segments, financial results, or future outlook.\n",
    "        - Expressions of enthusiasm, optimism, concern, caution, uncertainty, or defensiveness.\n",
    "        - Notable shifts in tone, especially during the Q&A section.\n",
    "        \n",
    "        Instructions:\n",
    "        - Identify the specific 'topic' being discussed.\n",
    "        - Determine the overall 'sentiment'.\n",
    "        - Attribute the sentiment to the correct 'speaker'. Use names if available, otherwise roles (CEO, CFO, Analyst).\n",
    "        - Provide a direct 'evidence' quote or concise summary from the transcript that supports your sentiment assessment.\n",
    "        - Ensure the 'quarter' field is correctly set to '{quarter}'.\n",
    "        \"\"\"\n",
    "        user_prompt = f\"Transcript for {quarter}:\n{transcript}\"\n",
    "        print(f\"SentimentAgent: Extracting insights for {quarter} using {STRUCTURED_MODEL_GOOGLE}...\")\n",
    "        insights = self._generate_json_insights(\n",
    "            client=client,\n",
    "            system_prompt=system_prompt,\n",
    "            user_prompt=user_prompt,\n",
    "            response_model=SentimentInsightsResponse,\n",
    "            model_name=STRUCTURED_MODEL_GOOGLE, # Pro likely better for nuanced sentiment\n",
    "            temperature=0.2 # Needs some flexibility for interpretation\n",
    "        )\n",
    "        print(f\"SentimentAgent: Completed for {quarter}. Found {len(insights)} insights.\")\n",
    "        return insights\n",
    "\n",
    "class RiskAgent(Agent):\n",
    "    def analyze(self, transcript: str, quarter: str, client: genai.GenerativeModel) -> List[RiskInsight]:\n",
    "        system_prompt = f\"\"\"\n",
    "        You are a risk analyst focused on identifying and extracting mentions of risks, challenges, uncertainties, and headwinds from the earnings call transcript for quarter {quarter}.\n",
    "        Focus on specific factors such as:\n",
    "        - Supply Chain: Disruptions, constraints, component shortages, logistics issues.\n",
    "        - Market/Demand: Uncertainty, softening demand, macroeconomic impacts, cyclicality.\n",
    "        - Competition: Increased pressure, new entrants, pricing pressure.\n",
    "        - Regulatory: New regulations, policy changes, compliance issues.\n",
    "        - Technology/Product: Development delays, technical challenges, execution risks.\n",
    "        - Geopolitical: International tensions, trade restrictions, regional instability.\n",
    "        - Execution Risks: Challenges in implementing strategy, scaling operations, M&A integration.\n",
    "        \n",
    "        Instructions:\n",
    "        - Identify the specific 'risk_factor'.\n",
    "        - Provide a 'description' of the risk as discussed.\n",
    "        - Note the 'potential_impact' if mentioned.\n",
    "        - Include any 'mitigation_mentioned' strategies discussed by management.\n",
    "        - Assign a 'severity' score (1-5, 5=most severe) based on the language used, emphasis, and potential impact described.\n",
    "        - Ensure the 'quarter' field is correctly set to '{quarter}'.\n",
    "        \"\"\"\n",
    "        user_prompt = f\"Transcript for {quarter}:\n{transcript}\"\n",
    "        print(f\"RiskAgent: Extracting insights for {quarter} using {STRUCTURED_MODEL_GOOGLE}...\")\n",
    "        insights = self._generate_json_insights(\n",
    "            client=client,\n",
    "            system_prompt=system_prompt,\n",
    "            user_prompt=user_prompt,\n",
    "            response_model=RiskInsightsResponse,\n",
    "            model_name=STRUCTURED_MODEL_GOOGLE,\n",
    "            temperature=0.1 \n",
    "        )\n",
    "        print(f\"RiskAgent: Completed for {quarter}. Found {len(insights)} insights.\")\n",
    "        return insights\n",
    "\n",
    "class CompetitorAgent(Agent):\n",
    "    def analyze(self, transcript: str, quarter: str, client: genai.GenerativeModel) -> List[CompetitorInsight]:\n",
    "        system_prompt = f\"\"\"\n",
    "        You are a competitive intelligence analyst. Your goal is to extract insights about the company's competitive landscape and positioning from the earnings call transcript for quarter {quarter}.\n",
    "        Focus on:\n",
    "        - Direct mentions of specific 'competitor' names.\n",
    "        - Discussion of specific 'market_segment'(s) where competition is relevant.\n",
    "        - Statements describing the company's 'positioning' relative to competitors (e.g., advantages, disadvantages, differentiation, market share comments).\n",
    "        - Commentary on competitive dynamics, threats, or responses to competitor actions.\n",
    "        - Identification of emerging competitive threats.\n",
    "        \n",
    "        Instructions:\n",
    "        - Extract the 'competitor' name if explicitly stated.\n",
    "        - Identify the relevant 'market_segment'.\n",
    "        - Capture the core statement about competitive 'positioning'.\n",
    "        - Note who 'mentioned_by' the information (e.g., CEO, CFO, Analyst Name).\n",
    "        - Ensure the 'quarter' field is correctly set to '{quarter}'.\n",
    "        \"\"\"\n",
    "        user_prompt = f\"Transcript for {quarter}:\n{transcript}\"\n",
    "        print(f\"CompetitorAgent: Extracting insights for {quarter} using {STRUCTURED_MODEL_GOOGLE}...\")\n",
    "        insights = self._generate_json_insights(\n",
    "            client=client,\n",
    "            system_prompt=system_prompt,\n",
    "            user_prompt=user_prompt,\n",
    "            response_model=CompetitorInsightsResponse,\n",
    "            model_name=STRUCTURED_MODEL_GOOGLE,\n",
    "            temperature=0.1\n",
    "        )\n",
    "        print(f\"CompetitorAgent: Completed for {quarter}. Found {len(insights)} insights.\")\n",
    "        return insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Analysis Agent\n",
    "\n",
    "Analyzes insights collected across multiple quarters to identify trends and shifts over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalAnalysisAgent(Agent):\n",
    "    \"\"\"Agent for analyzing trends across quarters based on previously extracted insights.\"\"\"\n",
    "\n",
    "    def analyze(self, all_insights_dict: Dict, client: genai.GenerativeModel) -> List[TemporalInsight]: # Takes dicts now\n",
    "        \"\"\"Analyze trends and patterns across quarters from the provided insights dictionary.\"\"\"\n",
    "        \n",
    "        # Format the input insights dictionary into a string for the LLM prompt\n",
    "        print(\"Formatting insights for temporal analysis...\")\n",
    "        formatted_insights = self._format_insights_for_analysis(all_insights_dict)\n",
    "        \n",
    "        if not formatted_insights or len(formatted_insights) < 100: # Basic check if formatting yielded anything substantial\n",
    "             print(\"Warning: Insufficient insights provided or formatting failed. Skipping temporal analysis.\")\n",
    "             return []\n",
    "             \n",
    "        # Determine the quarters present in the input data for the prompt\n",
    "        present_quarters = set()\n",
    "        for insight_type in all_insights_dict:\n",
    "            present_quarters.update(all_insights_dict[insight_type].keys())\n",
    "        quarters_str = ', '.join(sorted(list(present_quarters), key=lambda q: int(q[1]))) if present_quarters else \"provided quarters\"\n",
    "\n",
    "        system_prompt = f\"\"\"\n",
    "        You are a sophisticated trend analyst. Your task is to identify significant patterns, shifts, and developments across the earnings call insights provided for {quarters_str}. \n",
    "        Analyze the data *only* within the provided insights text below. Do NOT infer external knowledge.\n",
    "        Focus on identifying meaningful trends related to:\n",
    "        - Financial Performance: Consistent growth/decline trajectories, margin evolution, changes in guidance reliability.\n",
    "        - Strategic Direction: Evolution of key initiatives, changing priorities, consistency of vision.\n",
    "        - Sentiment: Overall tone shifts, recurring positive/negative sentiment on specific topics.\n",
    "        - Risk Landscape: Persistent risks, changes in perceived severity, emergence/resolution of risks.\n",
    "        - Competitive Environment: Evolution of commentary on competitors, market share, or positioning.\n",
    "        \n",
    "        Instructions:\n",
    "        - Identify the 'trend_type' (growth, decline, stable, volatile, emerging, fading).\n",
    "        - Specify the 'topic' the trend relates to.\n",
    "        - Provide a concise 'description' explaining the trend and its significance based on the data.\n",
    "        - List the 'quarters_observed' where this trend is evident in the input insights.\n",
    "        - Provide brief 'supporting_evidence' by summarizing key data points or recurring themes from the input insights text that demonstrate the trend.\n",
    "        \"\"\"\n",
    "        user_prompt = f\"Analyze the following structured insights across quarters to identify trends and patterns:\\n\\n{formatted_insights}\"\n",
    "        \n",
    "        # Limit prompt size if needed (Gemini Pro has large context, but good practice)\n",
    "        # MAX_PROMPT_TOKENS = 100000 # Example limit\n",
    "        # if estimate_tokens(user_prompt) > MAX_PROMPT_TOKENS:\n",
    "        #    print(\"Warning: Truncating input prompt for temporal analysis due to length.\")\n",
    "        #    user_prompt = truncate_prompt(user_prompt, MAX_PROMPT_TOKENS)\n",
    "            \n",
    "        print(f\"TemporalAnalysisAgent: Analyzing trends across {quarters_str} using {STRUCTURED_MODEL_GOOGLE}...\")\n",
    "        insights = self._generate_json_insights(\n",
    "            client=client,\n",
    "            system_prompt=system_prompt,\n",
    "            user_prompt=user_prompt,\n",
    "            response_model=TemporalInsightsResponse,\n",
    "            model_name=STRUCTURED_MODEL_GOOGLE, # Pro needed for complex synthesis\n",
    "            temperature=0.2 # Allow some synthesis ability\n",
    "        )\n",
    "        print(f\"TemporalAnalysisAgent: Completed. Found {len(insights)} trends.\")\n",
    "        return insights\n",
    "\n",
    "    def _format_insights_for_analysis(self, all_insights_dict: Dict, max_insights_per_type_quarter=20) -> str:\n",
    "        \"\"\"Format all insights from the dictionary into a structured string for the temporal analysis prompt.\"\"\"\n",
    "        formatted = \"Input Insights Data:\\n\"\n",
    "        formatted += \"====================\\n\"\n",
    "        \n",
    "        # Sort insight types for consistency\n",
    "        insight_types_sorted = sorted(all_insights_dict.keys())\n",
    "        \n",
    "        for agent_type in insight_types_sorted:\n",
    "            quarters_data = all_insights_dict.get(agent_type, {})\n",
    "            if not quarters_data: continue # Skip empty insight types\n",
    "            \n",
    "            formatted += f\"\\n## {agent_type.capitalize()} Insights:\\n\"\n",
    "            \n",
    "            # Sort quarters (Q1, Q2, Q3, Q4)\n",
    "            sorted_quarters = sorted(quarters_data.keys(), key=lambda q: int(q[1]))\n",
    "            \n",
    "            for quarter in sorted_quarters:\n",
    "                 insights = quarters_data.get(quarter, [])\n",
    "                 if not insights or not isinstance(insights, list): continue # Skip empty or invalid quarters\n",
    "                 \n",
    "                 formatted += f\"\\n### {quarter}:\\n\"\n",
    "                 \n",
    "                 # Limit insights per quarter to avoid excessively long prompts\n",
    "                 insights_to_include = insights[:max_insights_per_type_quarter]\n",
    "                 \n",
    "                 for i, insight in enumerate(insights_to_include):\n",
    "                     try:\n",
    "                         # Use compact JSON representation for each insight dictionary\n",
    "                         if isinstance(insight, dict):\n",
    "                             insight_str = json.dumps(insight, separators=(',', ':'), ensure_ascii=False) # Most compact\n",
    "                         else:\n",
    "                             insight_str = str(insight) # Fallback\n",
    "                         formatted += f\"- {insight_str}\\n\"\n",
    "                     except Exception as e:\n",
    "                          formatted += f\"- Error formatting insight: {e}\\n\"\n",
    "                          \n",
    "                 if len(insights) > len(insights_to_include):\n",
    "                      omitted_count = len(insights) - len(insights_to_include)\n",
    "                      formatted += f\"- ...(omitted {omitted_count} more {agent_type} insights for {quarter})\\n\"\n",
    "                      \n",
    "        formatted += \"\\n====================\\n\"\n",
    "        formatted += \"End of Input Insights Data.\\n\"\n",
    "        return formatted.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Processor\n",
    "\n",
    "Analyzes the user's natural language query to determine which quarters, agents, and analyses are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryProcessor:\n",
    "    \"\"\"Processes user queries to determine workflow requirements using Gemini.\"\"\"\n",
    "\n",
    "    def analyze_query(self, query: str, company: str, client: genai.GenerativeModel) -> Optional[QueryAnalysis]:\n",
    "        \"\"\"Analyze user query using Gemini JSON mode to determine required components.\"\"\"\n",
    "        \n",
    "        # Define the schema for the expected JSON output directly in the prompt\n",
    "        query_analysis_schema = QueryAnalysis.model_json_schema(indent=2)\n",
    "        \n",
    "        system_prompt = f\"\"\"\n",
    "        You are a query analysis assistant for {company}'s 2025 earnings call data. Your task is to interpret the user's query and determine the necessary parameters for analysis.\n",
    "\n",
    "        Follow these steps precisely:\n",
    "        1.  **Identify Quarters:** Determine the relevant quarter(s) (Q1, Q2, Q3, Q4 of 2025) mentioned or implied in the query. If the query spans the year or multiple quarters, list all relevant ones (e.g., ['Q1', 'Q2', 'Q3', 'Q4']). If uncertain, assume all four quarters: ['Q1', 'Q2', 'Q3', 'Q4'].\n",
    "        2.  **Identify Agent Types:** Select the necessary agent types from the list: [\"Financial\", \"Strategic\", \"Sentiment\", \"Risk\", \"Competitor\"]. Choose based on keywords (e.g., 'revenue' -> Financial; 'strategy', 'roadmap' -> Strategic; 'risk', 'challenge' -> Risk; 'feel', 'confident', 'tone' -> Sentiment; 'competitors', 'market share' -> Competitor).\n",
    "        3.  **Determine Temporal Need:** Set 'temporal_analysis_required' to `true` if the query explicitly asks for trends, comparisons over time, evolution, shifts, or uses phrases like 'across the year', 'how did X change', 'Q3 vs Q4'. Set to `false` if it asks about a single point in time or aggregates without comparison. If multiple quarters are requested but no comparison is explicitly asked, usually set to `false`.\n",
    "        4.  **Summarize Intent:** Provide a brief, clear 'query_intent' describing the user's main goal.\n",
    "        \n",
    "        You MUST respond ONLY with a valid JSON object that strictly adheres to the following Pydantic schema. Do NOT include any other text, explanations, or markdown formatting before or after the JSON object.\n",
    "        \n",
    "        Schema:\n",
    "        ```json\n",
    "        {query_analysis_schema}\n",
    "        ```\n",
    "        \"\"\"\n",
    "        user_prompt = f\"Analyze this query about {company}'s 2025 earnings: \\\"{query}\\\"\"\n",
    "\n",
    "        print(f\"QueryProcessor: Analyzing query \"{query}\" using {STRUCTURED_MODEL_GOOGLE}...\")\n",
    "        \n",
    "        contents = [system_prompt + \"\\n\\nUser Query to Analyze:\\n\" + user_prompt] # Combine into one prompt for the user role\n",
    "        \n",
    "        generation_config = types.GenerationConfig(\n",
    "            temperature=0.0, # Deterministic for analysis\n",
    "            response_mime_type=\"application/json\"\n",
    "        )\n",
    "\n",
    "        response_text = \"\"\n",
    "        parsed_json = None\n",
    "        try:\n",
    "            response = generate_content_with_retry(\n",
    "                client=client,\n",
    "                model_name=STRUCTURED_MODEL_GOOGLE,\n",
    "                contents=contents,\n",
    "                generation_config=generation_config\n",
    "            )\n",
    "            \n",
    "            response_text = response.text.strip()\n",
    "            if response_text.startswith(\"```json\"): response_text = response_text[7:-3].strip()\n",
    "            elif response_text.startswith(\"```\"): response_text = response_text[3:-3].strip()\n",
    "            \n",
    "            if not response_text:\n",
    "                 print(\"ðŸ›‘ Error: Received empty response text during query analysis.\")\n",
    "                 return None\n",
    "                 \n",
    "            parsed_json = json.loads(response_text)\n",
    "            query_analysis = QueryAnalysis(**parsed_json)\n",
    "\n",
    "            print(\"âœ… Query analysis completed:\")\n",
    "            print(f\"  > Quarters: {query_analysis.quarters}\")\n",
    "            print(f\"  > Agent Types: {query_analysis.agent_types}\")\n",
    "            print(f\"  > Temporal Analysis: {query_analysis.temporal_analysis_required}\")\n",
    "            print(f\"  > Intent: {query_analysis.query_intent}\")\n",
    "            return query_analysis\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"ðŸ›‘ Error decoding JSON during query analysis: {e}\")\n",
    "            print(f\"Received text: '{response_text[:500]}...'\" if response_text else \"Received empty text.\")\n",
    "            return None\n",
    "        except ValidationError as e:\n",
    "            print(f\"ðŸ›‘ Pydantic validation error during query analysis: {e}\")\n",
    "            # print(f\"Parsed JSON: {parsed_json}\") # Uncomment for debugging\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            # Catch errors from generate_content_with_retry or other issues\n",
    "            print(f\"ðŸ›‘ An unexpected error occurred during query analysis: {type(e).__name__}: {e}\")\n",
    "            traceback.print_exc()\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orchestration Layer\n",
    "\n",
    "The `EarningsCallAnalysisOrchestrator` coordinates the entire workflow: processing transcripts, managing agents, storing insights, generating reports, and answering queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarningsCallAnalysisOrchestrator:\n",
    "    \"\"\"Orchestrates the earnings call analysis workflow using Google GenAI.\"\"\"\n",
    "\n",
    "    def __init__(self, company: str, year: str, client: genai.GenerativeModel):\n",
    "        if client is None:\n",
    "            raise ValueError(\"Google GenAI client is not initialized. Cannot create orchestrator.\")\n",
    "            \n",
    "        self.company = company\n",
    "        self.year = year\n",
    "        self.client = client # Store the configured GenAI client\n",
    "        self.insights_store = InsightsStore(company, year)\n",
    "\n",
    "        # Initialize agents (client is passed during analysis)\n",
    "        self.financial_agent = FinancialAgent()\n",
    "        self.strategic_agent = StrategicAgent()\n",
    "        self.sentiment_agent = SentimentAgent()\n",
    "        self.risk_agent = RiskAgent()\n",
    "        self.competitor_agent = CompetitorAgent()\n",
    "        self.temporal_agent = TemporalAnalysisAgent()\n",
    "        self.query_processor = QueryProcessor()\n",
    "        print(\"Orchestrator initialized with all agents.\")\n",
    "\n",
    "    def process_transcript(self, quarter: Literal[\"Q1\", \"Q2\", \"Q3\", \"Q4\"]):\n",
    "        \"\"\"Process a single quarterly transcript: parse, analyze with all agents, store insights.\"\"\"\n",
    "        print(f\"\\n{'='*10} Processing {self.company} {self.year} {quarter} Transcript {'='*10}\")\n",
    "        processed_successfully = False\n",
    "        try:\n",
    "            # 1. Get Transcript (from cache or parsing)\n",
    "            transcript = PDFParser.get_transcript_by_quarter(self.company, quarter, self.year, self.client)\n",
    "            if not transcript or len(transcript) < 200: # Basic check for meaningful content\n",
    "                 print(f\"âš ï¸ Warning: Transcript for {quarter} is too short or empty. Skipping analysis.\")\n",
    "                 return False\n",
    "            else:\n",
    "                 print(f\"Transcript obtained for {quarter} (length: {len(transcript)} chars).\")\n",
    "\n",
    "            # 2. Run Analysis Agents (Sequentially)\n",
    "            # Consider parallel execution (e.g., using asyncio or ThreadPoolExecutor) for performance\n",
    "            # if API latency is the bottleneck and quota allows.\n",
    "            agent_insights = {}\n",
    "            agents_to_run = {\n",
    "                \"financial\": self.financial_agent,\n",
    "                \"strategic\": self.strategic_agent,\n",
    "                \"sentiment\": self.sentiment_agent,\n",
    "                \"risk\": self.risk_agent,\n",
    "                \"competitor\": self.competitor_agent\n",
    "            }\n",
    "\n",
    "            for agent_name, agent_instance in agents_to_run.items():\n",
    "                try:\n",
    "                    # Pass the client to the agent's analyze method\n",
    "                    insights = agent_instance.analyze(transcript, quarter, self.client)\n",
    "                    if insights: # Only store if insights were found\n",
    "                        agent_insights[agent_name] = insights\n",
    "                    else:\n",
    "                        print(f\"No insights found by {agent_name.capitalize()}Agent for {quarter}.\")\n",
    "                    # Optional delay between agent calls if hitting strict QPS limits\n",
    "                    # time.sleep(1)\n",
    "                except Exception as agent_error:\n",
    "                     print(f\"ðŸ›‘ ERROR running {agent_name.capitalize()}Agent for {quarter}: {agent_error}\")\n",
    "                     # Decide if failure of one agent should stop the whole process\n",
    "                     # For now, continue with other agents\n",
    "                     traceback.print_exc()\n",
    "\n",
    "            # 3. Store Insights\n",
    "            if not agent_insights:\n",
    "                 print(f\"No insights were generated by any agent for {quarter}. Nothing to store.\")\n",
    "            else:\n",
    "                 print(f\"Storing insights generated for {quarter}...\")\n",
    "                 for agent_name, insights in agent_insights.items():\n",
    "                     self.insights_store.add_insights(agent_name, quarter, insights)\n",
    "\n",
    "            processed_successfully = True\n",
    "            print(f\"{'='*10} Completed processing {self.company} {self.year} {quarter} Transcript {'='*10}\\n\")\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "             # Already handled within get_transcript_by_quarter, but catch again just in case\n",
    "             print(f\"ðŸ›‘ ERROR: Transcript file not found for {quarter}. Processing aborted. {e}\")\n",
    "        except Exception as e:\n",
    "            # Catch potential errors from parsing or agent execution\n",
    "            print(f\"ðŸ›‘ ERROR processing transcript for {quarter}: {type(e).__name__}: {e}\")\n",
    "            traceback.print_exc()\n",
    "        finally:\n",
    "             # Return status regardless of how function exits\n",
    "             return processed_successfully\n",
    "\n",
    "\n",
    "    def process_all_transcripts(self):\n",
    "        \"\"\"Process all four quarterly transcripts for the configured year.\"\"\"\n",
    "        print(f\"\\n{'='*15} Processing All Transcripts for {self.company} {self.year} {'='*15}\")\n",
    "        all_success = True\n",
    "        quarters_to_process: List[Literal[\"Q1\", \"Q2\", \"Q3\", \"Q4\"]] = [\"Q1\", \"Q2\", \"Q3\", \"Q4\"]\n",
    "        \n",
    "        for quarter in quarters_to_process:\n",
    "            # Optional: Check if insights already exist to skip reprocessing\n",
    "            # Example: Check if financial insights exist for this quarter\n",
    "            existing_financial_insights = self.insights_store.get_insights(\"financial\", [quarter])\n",
    "            if existing_financial_insights.get(quarter):\n",
    "                print(f\"âœ… Insights for {quarter} already exist in the store. Skipping processing.\")\n",
    "                continue\n",
    "            \n",
    "            # Process the transcript for the quarter\n",
    "            success = self.process_transcript(quarter)\n",
    "            if not success:\n",
    "                 print(f\"âš ï¸ Processing failed for {quarter}. Subsequent analysis might be incomplete.\")\n",
    "            all_success = all_success and success\n",
    "            \n",
    "            # Optional: Add delay between processing quarters if hitting rate limits\n",
    "            # print(\"Pausing before next quarter...\")\n",
    "            # time.sleep(5) \n",
    "            \n",
    "        print(f\"{'='*15} Finished Processing All Transcripts {'='*15}\")\n",
    "        return all_success\n",
    "\n",
    "    def generate_comprehensive_report(self, quarters: Optional[List[Literal[\"Q1\", \"Q2\", \"Q3\", \"Q4\"]]] = None):\n",
    "        \"\"\"Generate a comprehensive markdown report for specified or all quarters.\"\"\"\n",
    "        if quarters is None:\n",
    "            quarters = [\"Q1\", \"Q2\", \"Q3\", \"Q4\"]\n",
    "        # Ensure unique and sorted quarters\n",
    "        quarters = sorted(list(set(quarters)), key=lambda q: int(q[1])) \n",
    "        quarters_str = ', '.join(quarters)\n",
    "\n",
    "        print(f\"\\n{'='*10} Generating Comprehensive Report for {quarters_str} {'='*10}\")\n",
    "\n",
    "        # 1. Ensure needed insights are available (attempt processing if missing)\n",
    "        print(\"Checking for necessary insights...\")\n",
    "        insight_types_needed = [\"financial\", \"strategic\", \"sentiment\", \"risk\", \"competitor\"]\n",
    "        for quarter in quarters:\n",
    "            # Check if *any* core insight type is missing for this quarter\n",
    "            if not any(self.insights_store.get_insights(it, [quarter]).get(quarter) for it in insight_types_needed):\n",
    "                 print(f\"Insights for {quarter} seem missing. Attempting processing...\")\n",
    "                 processed = self.process_transcript(quarter)\n",
    "                 if not processed:\n",
    "                      print(f\"âš ï¸ Warning: Failed to process transcript for {quarter}. Report may be incomplete.\")\n",
    "                 else:\n",
    "                      print(f\"Successfully processed {quarter} to generate missing insights.\")\n",
    "\n",
    "        # 2. Get all insights (as dicts) required for report generation prompts\n",
    "        all_insights_dict = {\n",
    "            insight_type: self.insights_store.get_insights(insight_type, quarters)\n",
    "            for insight_type in insight_types_needed\n",
    "        }\n",
    "\n",
    "        # 3. Run Temporal Analysis if multiple quarters\n",
    "        temporal_insights = [] # List of TemporalInsight models\n",
    "        if len(quarters) > 1:\n",
    "            quarters_key = \"_vs_\".join(quarters) # Consistent key for this set of quarters\n",
    "            print(f\"Checking cache/generating temporal insights for key: {quarters_key}...\")\n",
    "            # Check cache first\n",
    "            cached_temporal_dict = self.insights_store.get_insights(\"temporal\", [quarters_key])\n",
    "            if cached_temporal_dict.get(quarters_key):\n",
    "                 print(f\"âœ… Using cached temporal insights for '{quarters_key}'.\")\n",
    "                 # Deserialize dicts back to models for consistency\n",
    "                 temporal_insights_dicts = cached_temporal_dict[quarters_key]\n",
    "                 try:\n",
    "                     temporal_insights = [TemporalInsight(**t_dict) for t_dict in temporal_insights_dicts]\n",
    "                 except (ValidationError, TypeError) as e:\n",
    "                      print(f\"âš ï¸ Warning: Validation error loading cached temporal insights: {e}. Will regenerate.\")\n",
    "                      temporal_insights = [] # Fallback\n",
    "            \n",
    "            # If not in cache or loading failed, generate them\n",
    "            if not temporal_insights:\n",
    "                 print(f\"Generating new temporal insights for quarters: {quarters_str}...\")\n",
    "                 # Pass the dictionary of insights to the temporal agent\n",
    "                 temporal_insights = self.temporal_agent.analyze(all_insights_dict, self.client)\n",
    "                 if temporal_insights:\n",
    "                     # Store the newly generated insights (as models, add_insights handles dict conversion)\n",
    "                     self.insights_store.add_insights(\"temporal\", quarters_key, temporal_insights)\n",
    "                 else:\n",
    "                     print(\"Temporal analysis returned no insights.\")\n",
    "        else:\n",
    "            print(\"Skipping temporal analysis (only one quarter requested).\")\n",
    "\n",
    "        # 4. Generate Report Sections (using text generation model)\n",
    "        report_sections = self._generate_report_sections(quarters, all_insights_dict, temporal_insights)\n",
    "\n",
    "        # 5. Compile Final Report\n",
    "        report_content = self._compile_report(report_sections, quarters)\n",
    "\n",
    "        # 6. Save Report to File\n",
    "        output_filename = f\"{self.company}_{self.year}_{'_'.join(quarters)}_Analysis_Google.md\"\n",
    "        output_path = Path(output_filename)\n",
    "        try:\n",
    "            output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(report_content)\n",
    "            print(f\"\\nâœ… Report saved successfully to: {output_path.resolve()}\")\n",
    "            return str(output_path), report_content\n",
    "        except IOError as e:\n",
    "             print(f\"ðŸ›‘ Error saving report to {output_path}: {e}\")\n",
    "             return None, report_content # Return content even if save fails\n",
    "\n",
    "    def answer_query(self, query: str):\n",
    "        \"\"\"Answer a specific user query based on stored or generated insights.\"\"\"\n",
    "        print(f\"\\n{'='*10} Processing Query: \"{query}\" {'='*10}\")\n",
    "\n",
    "        # 1. Analyze Query\n",
    "        query_analysis = self.query_processor.analyze_query(query, self.company, self.client)\n",
    "        if not query_analysis:\n",
    "             print(\"ðŸ›‘ Failed to analyze query. Cannot provide an answer.\")\n",
    "             return \"Sorry, I encountered an error understanding your query. Please try rephrasing.\"\n",
    "             \n",
    "        # Ensure required quarters are unique and sorted\n",
    "        required_quarters = sorted(list(set(query_analysis.quarters)), key=lambda q: int(q[1]))\n",
    "        if not required_quarters:\n",
    "             print(\"ðŸ›‘ Query analysis did not identify any relevant quarters. Cannot proceed.\")\n",
    "             return \"Sorry, I couldn't determine which quarters are relevant to your query.\"\n",
    "             \n",
    "        # 2. Ensure Necessary Insights are Available\n",
    "        print(f\"Checking insights for required quarters: {', '.join(required_quarters)} and types: {', '.join(query_analysis.agent_types)}...\")\n",
    "        for quarter in required_quarters:\n",
    "            # Check if any of the *required* agent types are missing for this quarter\n",
    "            if not any(self.insights_store.get_insights(agent_type.lower(), [quarter]).get(quarter) \n",
    "                       for agent_type in query_analysis.agent_types):\n",
    "                 print(f\"Required insights for {quarter} seem missing. Attempting processing...\")\n",
    "                 processed = self.process_transcript(quarter)\n",
    "                 if not processed:\n",
    "                       print(f\"âš ï¸ Warning: Failed to process transcript for {quarter}. Query answer may be incomplete.\")\n",
    "                 else:\n",
    "                      print(f\"Successfully processed {quarter} for query.\")\n",
    "\n",
    "        # 3. Collect Relevant Insights (as dicts for prompt generation)\n",
    "        relevant_insights_dict = {}\n",
    "        for agent_type in query_analysis.agent_types:\n",
    "            agent_key = agent_type.lower()\n",
    "            relevant_insights_dict[agent_key] = self.insights_store.get_insights(agent_key, required_quarters)\n",
    "            \n",
    "        # Check if any relevant insights were actually found\n",
    "        if not any(relevant_insights_dict.values()):\n",
    "             print(\"âš ï¸ No relevant insights found in the store for this query's criteria.\")\n",
    "             # Allow generation anyway, model might say info not found\n",
    "\n",
    "        # 4. Get/Generate Temporal Insights if Needed\n",
    "        temporal_insights = [] # List of TemporalInsight models\n",
    "        if query_analysis.temporal_analysis_required and len(required_quarters) > 1:\n",
    "            quarters_key = \"_vs_\".join(required_quarters)\n",
    "            print(f\"Checking cache/generating temporal insights for query key: {quarters_key}...\")\n",
    "            cached_temporal_dict = self.insights_store.get_insights(\"temporal\", [quarters_key])\n",
    "            if cached_temporal_dict.get(quarters_key):\n",
    "                 print(f\"âœ… Using cached temporal insights for query '{quarters_key}'.\")\n",
    "                 try:\n",
    "                    temporal_insights = [TemporalInsight(**t_dict) for t_dict in cached_temporal_dict[quarters_key]]\n",
    "                 except (ValidationError, TypeError) as e:\n",
    "                      print(f\"âš ï¸ Warning: Validation error loading cached temporal insights for query: {e}. Will regenerate.\")\n",
    "                      temporal_insights = []\n",
    "            \n",
    "            if not temporal_insights:\n",
    "                 print(f\"Generating new temporal insights for query quarters: {', '.join(required_quarters)}...\")\n",
    "                 # Need to pass the relevant insight dicts to the temporal agent\n",
    "                 temporal_insights = self.temporal_agent.analyze(relevant_insights_dict, self.client)\n",
    "                 if temporal_insights:\n",
    "                     self.insights_store.add_insights(\"temporal\", quarters_key, temporal_insights)\n",
    "                 else:\n",
    "                      print(\"Temporal analysis for query returned no insights.\")\n",
    "        elif query_analysis.temporal_analysis_required:\n",
    "             print(\"Temporal analysis requested but only one quarter identified. Skipping.\")\n",
    "\n",
    "        # 5. Generate Response using Text Generation Model\n",
    "        response_text = self._generate_query_response(\n",
    "            query=query,\n",
    "            query_analysis=query_analysis,\n",
    "            relevant_insights=relevant_insights_dict, # Pass dicts\n",
    "            temporal_insights=temporal_insights # Pass models\n",
    "        )\n",
    "\n",
    "        print(f\"{'='*10} Query Processing Completed {'='*10}\\n\")\n",
    "        return response_text\n",
    "\n",
    "    # --- Internal Helper Methods for Report Generation ---\n",
    "\n",
    "    def _generate_text_section(self, system_prompt: str, user_prompt: str, title: str) -> Dict:\n",
    "         \"\"\"Helper to generate text content for a report section using the default text model.\"\"\"\n",
    "         print(f\"Generating report section: '{title}' using {DEFAULT_MODEL_GOOGLE}...\")\n",
    "         \n",
    "         # Use simple string content for basic text generation\n",
    "         contents = [system_prompt + \"\\n\\nInput Data/Request:\\n\" + user_prompt]\n",
    "         \n",
    "         generation_config = types.GenerationConfig(\n",
    "             temperature=0.3, # Slightly creative for summaries/prose\n",
    "             # max_output_tokens=... # Optional: Limit response length\n",
    "             response_mime_type=\"text/plain\"\n",
    "         )\n",
    "\n",
    "         try:\n",
    "              response = generate_content_with_retry(\n",
    "                  client=self.client,\n",
    "                  model_name=DEFAULT_MODEL_GOOGLE,\n",
    "                  contents=contents,\n",
    "                  generation_config=generation_config\n",
    "              )\n",
    "              content = response.text\n",
    "              print(f\"âœ… Finished generating section: '{title}' ({len(content)} chars)\")\n",
    "              return {\"title\": title, \"content\": content}\n",
    "         except Exception as e:\n",
    "              print(f\"ðŸ›‘ Error generating report section '{title}': {type(e).__name__}: {e}\")\n",
    "              traceback.print_exc()\n",
    "              return {\"title\": title, \"content\": f\"*Error generating content for this section. Please check logs.*\"}\n",
    "\n",
    "    def _format_insights_for_prompt(self, insights_dict: Dict, is_temporal: bool = False, max_per_quarter: int = 15, max_temporal: int = 25) -> str:\n",
    "        \"\"\"Formats insights dict or list into a string suitable for LLM text generation prompts.\"\"\"\n",
    "        formatted = \"\"\n",
    "        \n",
    "        if is_temporal:\n",
    "             # Input is assumed to be a list of TemporalInsight models or dicts\n",
    "             temporal_insights = insights_dict \n",
    "             if not temporal_insights:\n",
    "                  return \"\\n## Temporal Trends:\\n- No relevant trends identified or provided.\\n\"\n",
    "                  \n",
    "             formatted += \"\\n## Temporal Trends:\\n\"\n",
    "             for i, insight in enumerate(temporal_insights[:max_temporal]):\n",
    "                 try:\n",
    "                     if hasattr(insight, 'model_dump'): insight_dict = insight.model_dump(mode='json')\n",
    "                     elif isinstance(insight, dict): insight_dict = insight\n",
    "                     else: insight_dict = {\"raw_content\": str(insight)}\n",
    "                     insight_str = json.dumps(insight_dict, ensure_ascii=False, indent=None) # Compact\n",
    "                     formatted += f\"- {insight_str}\\n\"\n",
    "                 except Exception as e:\n",
    "                      formatted += f\"- Error formatting temporal insight: {e}\\n\"\n",
    "             if len(temporal_insights) > max_temporal:\n",
    "                 formatted += f\"- ...(omitted {len(temporal_insights) - max_temporal} more temporal trends)\\n\"\n",
    "            \n",
    "        else:\n",
    "             # Input is a dictionary structured by {agent_type: {quarter: [insight_dicts]}}\n",
    "             insight_types_sorted = sorted(insights_dict.keys())\n",
    "             for agent_type in insight_types_sorted:\n",
    "                 quarters_data = insights_dict.get(agent_type, {})\n",
    "                 if not quarters_data: continue\n",
    "                 formatted += f\"\\n## {agent_type.capitalize()} Insights:\\n\"\n",
    "                 sorted_quarters = sorted(quarters_data.keys(), key=lambda q: int(q[1]))\n",
    "                 for quarter in sorted_quarters:\n",
    "                     insights = quarters_data.get(quarter, [])\n",
    "                     if not insights or not isinstance(insights, list): continue\n",
    "                     formatted += f\"\\n### {quarter}:\\n\"\n",
    "                     count = 0\n",
    "                     for insight in insights:\n",
    "                         if count >= max_per_quarter:\n",
    "                             formatted += f\"- ...(omitted {len(insights) - count} more {agent_type} insights for {quarter})\\n\"\n",
    "                             break\n",
    "                         try:\n",
    "                              if isinstance(insight, dict):\n",
    "                                  insight_str = json.dumps(insight, ensure_ascii=False, separators=(',', ':'))\n",
    "                              else:\n",
    "                                  insight_str = str(insight)\n",
    "                              formatted += f\"- {insight_str}\\n\"\n",
    "                              count += 1\n",
    "                         except Exception as e:\n",
    "                              formatted += f\"- Error formatting insight: {e}\\n\"\n",
    "                              \n",
    "        return formatted.strip()\n",
    "\n",
    "    def _generate_report_sections(self, quarters: List[str], all_insights: Dict, temporal_insights: List[TemporalInsight]):\n",
    "        \"\"\"Generate all sections for the comprehensive report using Gemini text generation.\"\"\"\n",
    "        print(\"Generating report sections...\")\n",
    "        report_sections = {}\n",
    "        quarters_str = ', '.join(quarters)\n",
    "        year = self.year\n",
    "        company = self.company\n",
    "\n",
    "        # --- Prepare Formatted Insights Strings --- \n",
    "        # For general sections (like Exec Summary) - combine all types\n",
    "        formatted_all_insights_brief = self._format_insights_for_prompt(all_insights, max_per_quarter=5) # Brief version for summary\n",
    "        formatted_temporal_brief = self._format_insights_for_prompt(temporal_insights, is_temporal=True, max_temporal=10) # Brief version\n",
    "\n",
    "        # For specific sections - format only relevant insights\n",
    "        formatted_financial = self._format_insights_for_prompt({'financial': all_insights.get('financial', {})}, max_per_quarter=20)\n",
    "        formatted_strategic = self._format_insights_for_prompt({'strategic': all_insights.get('strategic', {})}, max_per_quarter=15)\n",
    "        formatted_market = self._format_insights_for_prompt({\n",
    "             'competitor': all_insights.get('competitor', {}),\n",
    "             'sentiment': all_insights.get('sentiment', {}) # Include sentiment for market context\n",
    "        }, max_per_quarter=10)\n",
    "        formatted_risk = self._format_insights_for_prompt({'risk': all_insights.get('risk', {})}, max_per_quarter=15)\n",
    "        formatted_temporal_full = self._format_insights_for_prompt(temporal_insights, is_temporal=True) # Full version\n",
    "        \n",
    "        # --- Generate Sections --- \n",
    "        \n",
    "        # Executive Summary\n",
    "        sys_exec = f\"You are a senior analyst writing a concise Executive Summary for {company}'s {year} performance across {quarters_str}. Synthesize the key financial highlights, strategic moves, market shifts, risks, and overall trajectory based *only* on the provided insights. Use professional language and markdown formatting (bolding, bullets).\"\n",
    "        usr_exec = f\"Generate the Executive Summary based on this data:\\n{formatted_all_insights_brief}\\n{formatted_temporal_brief}\"\n",
    "        report_sections[\"executive_summary\"] = self._generate_text_section(sys_exec, usr_exec, \"Executive Summary\")\n",
    "\n",
    "        # Financial Performance\n",
    "        sys_fin = f\"You are a financial analyst detailing {company}'s financial performance ({year}, {quarters_str}). Analyze revenue, profitability, cash flow, KPIs, and guidance based *only* on the provided financial insights. Use markdown (subheadings, bullets, bolding) and cite specific figures/context.\"\n",
    "        usr_fin = f\"Generate the Financial Performance Analysis section using these financial insights:\\n{formatted_financial}\"\n",
    "        report_sections[\"financial_performance\"] = self._generate_text_section(sys_fin, usr_fin, \"Financial Performance Analysis\")\n",
    "\n",
    "        # Strategic Initiatives\n",
    "        sys_strat = f\"You are a strategy analyst detailing {company}'s strategic initiatives ({year}, {quarters_str}). Analyze priorities, product developments, partnerships, R&D, and market focus based *only* on the provided strategic insights. Note evolution if possible. Use markdown.\"\n",
    "        usr_strat = f\"Generate the Strategic Initiatives Analysis section using these strategic insights:\\n{formatted_strategic}\"\n",
    "        report_sections[\"strategic_initiatives\"] = self._generate_text_section(sys_strat, usr_strat, \"Strategic Initiatives Analysis\")\n",
    "\n",
    "        # Market Positioning\n",
    "        sys_mkt = f\"You are a market analyst detailing {company}'s competitive positioning ({year}, {quarters_str}). Analyze its stance in key segments, competitor dynamics, differentiation, and market sentiment based *only* on the provided competitor and sentiment insights. Use markdown.\"\n",
    "        usr_mkt = f\"Generate the Market Positioning Analysis section using these competitor and sentiment insights:\\n{formatted_market}\"\n",
    "        report_sections[\"market_positioning\"] = self._generate_text_section(sys_mkt, usr_mkt, \"Market Positioning Analysis\")\n",
    "\n",
    "        # Risk Assessment\n",
    "        sys_risk = f\"You are a risk analyst detailing {company}'s risks and challenges ({year}, {quarters_str}). Analyze major risks, mitigations, severity, and evolution based *only* on the provided risk insights. Use markdown.\"\n",
    "        usr_risk = f\"Generate the Risk Assessment section using these risk insights:\\n{formatted_risk}\"\n",
    "        report_sections[\"risk_assessment\"] = self._generate_text_section(sys_risk, usr_risk, \"Risk Assessment\")\n",
    "\n",
    "        # Quarterly Trends (only if multiple quarters and trends exist)\n",
    "        if len(quarters) > 1 and temporal_insights:\n",
    "            sys_trends = f\"You are a business analyst summarizing key quarter-to-quarter trends for {company} ({year}, {quarters_str}). Synthesize the provided temporal trend insights into a narrative covering financial, strategic, risk, and market shifts. Highlight key inflection points. Use markdown.\"\n",
    "            usr_trends = f\"Generate the Quarterly Trends Analysis section using these identified trends:\\n{formatted_temporal_full}\"\n",
    "            report_sections[\"quarterly_trends\"] = self._generate_text_section(sys_trends, usr_trends, \"Quarterly Trends Analysis\")\n",
    "\n",
    "        # Outlook and Projections (only if Q4 or multiple quarters analyzed)\n",
    "        if \"Q4\" in quarters or len(quarters) > 1:\n",
    "             # Focus prompt on latest quarter + trends for outlook\n",
    "             latest_quarter = quarters[-1]\n",
    "             latest_insights_prompt = self._format_insights_for_prompt({\n",
    "                  k: ({latest_quarter: v[latest_quarter]} if isinstance(v.get(latest_quarter), list) else {}) \n",
    "                  for k, v in all_insights.items() if isinstance(v, dict)\n",
    "             }, max_per_quarter=15) # Show more from latest quarter\n",
    "             \n",
    "             sys_outlook = f\"You are a forward-looking analyst providing an Outlook for {company} based on {year} ({quarters_str}) insights. Summarize guidance, key future initiatives, potential opportunities/challenges, and trajectory based *only* on the provided insights, emphasizing {latest_quarter} and overall trends. Use markdown.\"\n",
    "             usr_outlook = f\"Generate the Outlook and Projections section using insights (focus on {latest_quarter} + trends):\\n{latest_insights_prompt}\\n{formatted_temporal_full}\"\n",
    "             report_sections[\"outlook\"] = self._generate_text_section(sys_outlook, usr_outlook, \"Outlook and Projections\")\n",
    "\n",
    "        print(\"âœ… All report sections generated.\")\n",
    "        return report_sections\n",
    "\n",
    "    def _compile_report(self, report_sections: Dict, quarters: List[str]) -> str:\n",
    "        \"\"\"Compile all generated sections into a final markdown report string.\"\"\"\n",
    "        print(\"Compiling final report markdown...\")\n",
    "        quarters_str = ', '.join(quarters)\n",
    "        title_period = f\"{self.year} ({quarters_str})\" if len(quarters) < 4 else f\"{self.year} Annual\"\n",
    "        \n",
    "        # --- Report Header ---\n",
    "        report_content = f\"# {self.company} {title_period} Earnings Call Analysis\\n\\n\"\n",
    "        report_content += f\"**Company:** {self.company}\\n\"\n",
    "        report_content += f\"**Period Analyzed:** {title_period}\\n\"\n",
    "        report_content += f\"**Generated On:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\"\n",
    "        report_content += f\"**Analysis Engine:** Google Gemini via Vertex AI\\n\\n\"\n",
    "        report_content += \"---\\n\"\n",
    "\n",
    "        # --- Report Body (Sections in Order) ---\n",
    "        section_order = [\n",
    "            \"executive_summary\", \"financial_performance\", \"strategic_initiatives\",\n",
    "            \"market_positioning\", \"risk_assessment\", \"quarterly_trends\", \"outlook\"\n",
    "        ]\n",
    "\n",
    "        for section_key in section_order:\n",
    "            if section_key in report_sections and report_sections[section_key]:\n",
    "                section = report_sections[section_key]\n",
    "                report_content += f\"\\n## {section.get('title', section_key.replace('_', ' ').title())}\\n\\n\"\n",
    "                # Basic cleanup for content - remove potential leading/trailing whitespace\n",
    "                content = section.get('content', '*No content generated for this section.*').strip()\n",
    "                report_content += f\"{content}\\n\\n\"\n",
    "                report_content += \"---\\n\" # Separator\n",
    "            # else:\n",
    "                # Optionally include a note if a section was expected but not generated\n",
    "                # if section_key in [\"quarterly_trends\", \"outlook\"]: # Only for optional sections\n",
    "                #     report_content += f\"\\n## {section_key.replace('_', ' ').title()}\\n\\n\"\n",
    "                #     report_content += \"*This section was not generated (e.g., insufficient data or single quarter analysis).*\\n\\n\"\n",
    "                #     report_content += \"---\\n\"\n",
    "\n",
    "        print(\"âœ… Report compilation finished.\")\n",
    "        return report_content\n",
    "\n",
    "    def _generate_query_response(self, query: str, query_analysis: QueryAnalysis, relevant_insights: Dict, temporal_insights: List[TemporalInsight]):\n",
    "        \"\"\"Generate the final response string to the user's query using Gemini.\"\"\"\n",
    "        print(f\"Generating response for query using {DEFAULT_MODEL_GOOGLE}...\")\n",
    "        \n",
    "        quarters_str = ', '.join(query_analysis.quarters)\n",
    "        agents_str = ', '.join(query_analysis.agent_types)\n",
    "        temporal_str = 'required' if query_analysis.temporal_analysis_required else 'not required'\n",
    "        \n",
    "        system_prompt = f\"\"\"\n",
    "        You are an expert AI analyst answering a query about {self.company}'s {self.year} earnings calls.\n",
    "        The query pertains to quarter(s): {quarters_str}.\n",
    "        Analysis considered: {agents_str}.\n",
    "        Temporal analysis (trends over time) was {temporal_str}.\n",
    "        \n",
    "        Your task is to answer the user's query below based *strictly* on the provided 'Supporting Insights' data. Do not use any external knowledge.\n",
    "        - Answer clearly and concisely.\n",
    "        - If the insights contain the necessary information, synthesize it into a direct answer.\n",
    "        - If the insights do *not* contain the information needed to answer the query, explicitly state that the information is not available in the provided data.\n",
    "        - Use markdown formatting for readability (bolding, bullets).\n",
    "        \"\"\"\n",
    "\n",
    "        # Format the insights data for the prompt\n",
    "        formatted_relevant_insights = self._format_insights_for_prompt(relevant_insights, max_per_quarter=20) # Show more details for queries\n",
    "        formatted_temporal = self._format_insights_for_prompt(temporal_insights, is_temporal=True) if query_analysis.temporal_analysis_required else \"\"\n",
    "\n",
    "        user_prompt = f\"\"\"\n",
    "        User Query: \"{query}\"\n",
    "        \n",
    "        Supporting Insights:\n",
    "        ====================\n",
    "        {formatted_relevant_insights}\n",
    "        {formatted_temporal}\n",
    "        ====================\n",
    "        End of Supporting Insights.\n",
    "        \n",
    "        Based only on the supporting insights provided above, answer the user query.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Use the text generation helper\n",
    "        response_section = self._generate_text_section(system_prompt, user_prompt, \"Query Response Content\")\n",
    "        return response_section['content'] # Return only the generated content string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Execution Block\n",
    "\n",
    "This section demonstrates the workflow:\n",
    "1.  Download sample NVIDIA earnings call transcript PDFs.\n",
    "2.  Initialize the Orchestrator.\n",
    "3.  Process all quarterly transcripts (parsing + agent analysis).\n",
    "4.  Generate a comprehensive annual report.\n",
    "5.  Answer several example queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_files = [\n",
    "    \"nvidia_earnings_2025_Q1.pdf\",\n",
    "    \"nvidia_earnings_2025_Q2.pdf\",\n",
    "    \"nvidia_earnings_2025_Q3.pdf\",\n",
    "    \"nvidia_earnings_2025_Q4.pdf\",\n",
    "]\n",
    "# Base URL from the original notebook - points to the Mistral cookbook repo\n",
    "base_url = \"https://github.com/mistralai/cookbook/blob/main/mistral/agents/earnings_calls/data/\"\n",
    "\n",
    "print(\"Checking for PDF transcript files...\")\n",
    "for pdf_file in pdf_files:\n",
    "    if not Path(pdf_file).exists():\n",
    "        download_url = f\"{base_url}{pdf_file}?raw=true\"\n",
    "        print(f\"Downloading {pdf_file} from {download_url}...\")\n",
    "        # Use !wget for simplicity in notebooks\n",
    "        !wget --quiet \"{download_url}\" -O \"{pdf_file}\"\n",
    "        # Verify download\n",
    "        if Path(pdf_file).exists() and Path(pdf_file).stat().st_size > 0:\n",
    "             print(f\"âœ… Downloaded {pdf_file}\")\n",
    "        else:\n",
    "             print(f\"ðŸ›‘ Failed to download {pdf_file}\")\n",
    "             # Handle error - maybe stop execution if files are crucial\n",
    "             # raise RuntimeError(f\"Failed to download required file: {pdf_file}\")\n",
    "    else:\n",
    "         print(f\"âœ… {pdf_file} already exists locally.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Initialize Orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company = \"NVIDIA\"\n",
    "year = \"2025\"\n",
    "orchestrator = None\n",
    "\n",
    "if google_client:\n",
    "    try:\n",
    "         print(f\"\\nInitializing orchestrator for {company} {year}...\")\n",
    "         orchestrator = EarningsCallAnalysisOrchestrator(company, year, google_client)\n",
    "         print(\"âœ… Orchestrator initialized successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ðŸ›‘ Error initializing orchestrator: {e}\")\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"ðŸ›‘ Cannot initialize orchestrator because Google GenAI client setup failed or was skipped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Process All Quarterly Transcripts\n",
    "\n",
    "(This step involves multiple LLM calls for parsing and analysis - may take some time and incur costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if orchestrator:\n",
    "    print(\"\\n--- Processing All Quarterly Transcripts --- \")\n",
    "    processing_status = orchestrator.process_all_transcripts()\n",
    "    if processing_status:\n",
    "        print(\"\\nâœ… Successfully processed (or found cached insights for) all transcripts.\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ Warning: Processing did not complete successfully for all transcripts.\")\n",
    "else:\n",
    "    print(\"ðŸ›‘ Skipping transcript processing because orchestrator is not initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Generate Comprehensive Annual Report\n",
    "\n",
    "(This involves additional LLM calls to synthesize insights into report sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "report_content = None\n",
    "report_file = None\n",
    "\n",
    "if orchestrator:\n",
    "    print(\"\\n--- Generating Comprehensive Annual Report --- \")\n",
    "    try:\n",
    "        # Specify all quarters for the annual report\n",
    "        annual_quarters: List[Literal[\"Q1\", \"Q2\", \"Q3\", \"Q4\"]] = [\"Q1\", \"Q2\", \"Q3\", \"Q4\"]\n",
    "        report_file, report_content = orchestrator.generate_comprehensive_report(annual_quarters)\n",
    "\n",
    "        if report_content and report_file:\n",
    "            print(f\"\\n--- Annual Report ({report_file}) --- \")\n",
    "            # Display the generated Markdown report directly in the notebook\n",
    "            display(Markdown(\"```markdown\\n\" + report_content + \"\\n```\")) # Wrap in markdown block for display\n",
    "        elif report_content:\n",
    "            print(\"Report content generated but saving failed. Displaying content:\")\n",
    "            display(Markdown(\"```markdown\\n\" + report_content + \"\\n```\"))\n",
    "        else:\n",
    "             print(\"ðŸ›‘ Failed to generate report content.\")\n",
    "             \n",
    "    except Exception as e:\n",
    "         print(f\"ðŸ›‘ An error occurred during report generation: {e}\")\n",
    "         traceback.print_exc()\n",
    "else:\n",
    "    print(\"ðŸ›‘ Skipping report generation because orchestrator is not initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Answer Specific Queries\n",
    "\n",
    "(Each query involves LLM calls for analysis and response generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if orchestrator:\n",
    "    print(\"\\n--- Answering Specific Queries --- \")\n",
    "\n",
    "    queries = [\n",
    "         \"What were the key financial metrics like revenue and EPS in Q1 and Q2?\",\n",
    "         \"Identify strategic shifts or key initiatives mentioned for NVIDIA's automotive business across the full year 2025.\",\n",
    "         \"What specific risks did NVIDIA highlight in their Q4 earnings call? How do these compare to risks mentioned in Q3?\",\n",
    "         \"How did the overall management sentiment or tone regarding the Data Center business evolve throughout the year?\",\n",
    "         \"Summarize the financial guidance provided in the Q4 call for the upcoming quarter or full year.\",\n",
    "         \"Were there any mentions of specific competitors in the gaming segment during Q2 or Q3?\"\n",
    "     ]\n",
    "\n",
    "    for i, query in enumerate(queries):\n",
    "        print(f\"\\n{'='*10} Query {i+1} {'='*10}\")\n",
    "        display(Markdown(f\"**Query:** {query}\"))\n",
    "        try:\n",
    "            answer = orchestrator.answer_query(query)\n",
    "            display(Markdown(\"**Answer:**\"))\n",
    "            display(Markdown(answer))\n",
    "        except Exception as e:\n",
    "            print(f\"ðŸ›‘ An error occurred answering query {i+1}: {e}\")\n",
    "            display(Markdown(\"**Answer:** *Error generating answer. Check logs.*\"))\n",
    "            traceback.print_exc()\n",
    "        \n",
    "        # Optional delay between queries if hitting rate limits\n",
    "        # print(\"Pausing before next query...\")\n",
    "        # time.sleep(5) \n",
    "        print(\"-\"*40)\n",
    "else:\n",
    "    print(\"ðŸ›‘ Skipping query answering because orchestrator is not initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- End of Notebook ---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}